<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0//EN">
<html><head>
<link rel="STYLESHEET" href="openpnlref.css" charset="ISO-8859-1" type="text/css">
<title>PNL: User Guide</title>
</head><body>

<center><table cellspacing=0 cellpadding=5 width="90%" bgcolor="#6a9bed" nosave >
<tr nosave>
<td nosave>
<center><i><font color="#000000"><font size=+4>
PNL: User Guide
</font></font></i></center>
</td>
</tr>
</table></center>


<hr><p>
<ul>
<li><a href="#ug_GrM">Graphical Models</a>

<li><a href="#ug_DGrM">Dynamic Graphical Models</a>

<li><a href="#ug_LIMID">Influence Diagrams</a></li>

<li><a href="#ug_Diagnostics">Diagnostic Networks</a></li>

<li><a href="#ug_Inf">Inference Algorithms for Bayesian and Markov Networks</a>

<li><a href="#ug_PBInf">Particle-based Inference</a>

<li><a href="#ug_InfDBN">Inference Algorithms for DBNs</a>

<li><a href="#ug_InfLIMID">Inference Algorithm for LIMIDs</a></li>

<li><a href="#ug_Learning">Learning for Bayesian and Markov Network</a>
<ul>
<li> <a href="#decl_Type1">Type 1</a>
<li> <a href="#decl_Type2">Type 2</a>
<li> <a href="#decl_Type3">Type 3</a>
</ul>

<li><a href="#ug_LearningDBN">Learning for DBNs</a>
<li>Sophisticated Distributions</li>
 <ul>
  <li><a href="#ug_SoftMax">SoftMax Distribution</a></li>
  <li><a href="#ug_DTree">Decision Tree Distribution</a></li>
 </ul>
<li><a href="#ug_LogSubsystem">Log Subsystem</a>
</ul></p>


<hr><h2><a name="ug_GrM">Graphical Models</a></h2>

<p>
A <i>Probabilistic graphical model</i> (PGM) is a factorized joint probability
distribution over a set of random variables which are called <i>model domain</i>. A
<i>factor</i> is a function defined on a small subset of variables called <i>factor domain</i>.
From the probabilistic viewpoint the factorized representation encodes
independence relationships, while from the technical viewpoint it relaxes strict
memory and computing power requirements for using PGMs, which allows
exploitation of models with large domains.
</p>
<p>
Probabilistic graphical models have three components:
<ul>
  <li>variables (model domain)
  <li>factorization type (structure)
  <li>factors proper.
</ul>
Variables of the model can be either discrete vectors, which take a finite
number of values, or continuous vectors.
</p>
<p>
All commonly used factorization types have a corresponding graph representation.
Nodes of a graph correspond to random variables. In this documentation we will
further identify the notion of a random variable with the notion of a node in a
graph. Edges of the graph reflect the factorization of the joint probability
distribution.
</p>
<p>
PNL implements some important classes of graphical models:
<ul>
  <li><i>Markov Random Fields (MRFs)</i>, also called <i>Markov Networks (MNets)</i>, that are
characterized by undirected graphs. The domain of each factor is a number of
nodes of the graph, which form a clique.</li>
<li><i>Bayesian Networks (BNets)</i> are represented by directed acyclic graphs (DAG),
where each factor is associated with a child node and has the domain consisting
of all parent nodes and the child node.</li>
</ul>
</p>
<p>
A factor in a Bayesian Network has the form of <i>conditional probability distribution (CPD)</i>
for a child node, with its parent nodes provided. In this
context a directed edge from node A to node B may be interpreted as a causal
relationship, though the absence of the edge does not mean that nodes are
statistically independent.
</p>
<p>
The third constituent of a graphical model is a factor. It may have different
forms and functionality depending on the type of the model. MRF factors are
arbitrary positive functions called potentials. BNet factors are CPDs - positive
functions that sum to 1 over the child node regardless of parent node values.
</p>
<p>
A graphical model is created in PNL by the routine shown in Example 2-1. The
routine applies to Bayesian networks and with some changes - to Markov Networks.
The model of the example is called "water-sprinkler". The graph structure of the
model and its parameters (CPDs) are all shown in <a href="#figWaterSprinkler"> Figure 2-1 </a>:
</p>

<hr><h4><a name="figWaterSprinkler"> Figure 2-1. Water-sprinkler model</a></h4>

<img align=center src="fig/ugfig2.gif">

<p>
The nodes are numbered as follows:
<ul>
  <li>Cloudy (C) = 0;
  <li>Sprinkler (S) = 1;
  <li>Rain (R) = 2;
  <li>Wet Grass (W) = 3
</ul>
</p>

<p>
PNL has special containers for storing scalar and vector data. A <tt>CValue</tt> object
is created to store inhomogeneous scalar data used as evidence. <tt>pnlVector</tt> is a
template that stores vector data. For the sake of brevity PNL defines several
synonyms to specializations of <tt>pnlVector.</tt> For more details see Reference Manual.
</p>

<hr>
<h4><a name="exWaterSprinkler">Example 2-1. Creation of water sprinkler Bayesian network</a></h4>

<pre>
// need to specify the graph structure of the model;
// there are two way to do it
CGraph *pGraph;
if(1)
{
    // Graph creation using adjacency matrix
    int numAdjMatDims = 2;
    int ranges[] = { numOfNds, numOfNds };
    intVector matrixData( numOfNds*numOfNds, 0 );
    CDenseMatrix<int>* adjMat = CDenseMatrix<int>::Create( numAdjMatDims, ranges, &amp;matrixData.front() );
    int indices[] = { 0, 1 };
    adjMat-&gt;SetElementByIndexes( 1, indices );
    indices[1] = 2;
    adjMat-&gt;SetElementByIndexes( 1, indices );
    indices[0] = 1;
    indices[1] = 3;
    adjMat-&gt;SetElementByIndexes( 1, indices );
    indices[0] = 2;
    adjMat-&gt;SetElementByIndexes( 1, indices );
    // this is a creation of directed graph for the BNet model based on
    //adjacency matrix
    pGraph = CGraph::Create(adjMat);
}
else
{
    // Graph creation using neighbors list
    int numOfNbrs[numOfNds] = { 2, 2, 2, 2 };
    int nbrs0[] = { 1, 2 };
    int nbrs1[] = { 0, 3 };
    int nbrs2[] = { 0, 3 };
    int nbrs3[] = { 1, 2 };
    // number of neighbors for every node
    int *nbrs[] = { nbrs0, nbrs1, nbrs2, nbrs3 };
    // neighbors can be of either one of the three following types:
    // a parent, a child (for directed arcs) or just a neighbor (for
    //undirected graphs).
    // Accordingly, the types are ntParent, ntChild or ntNeighbor.
    ENeighborType nbrsTypes0[] = { ntChild, ntChild };
    ENeighborType nbrsTypes1[] = { ntParent, ntChild };
    ENeighborType nbrsTypes2[] = { ntParent, ntChild };
    ENeighborType nbrsTypes3[] = { ntParent, ntParent };
    ENeighborType *nbrsTypes[] = { nbrsTypes0, nbrsTypes1, nbrsTypes2, nbrsTypes3 };
    // this is creation of a directed graph for the BNet model using neighbors list
    pGraph = CGraph::Create( numOfNds, numOfNbrs, nbrs, nbrsTypes );
}
// 2 STEP:
// Creation NodeType objects and specify node types for all nodes of the model.
nodeTypeVector nodeTypes;
// number of node types is 1, because all nodes are of the same type
// all four are discrete and binary
CNodeType nt(1,2);
nodeTypes.push_back(nt);
intVector nodeAssociation;
// reflects association between node numbers and node types
// nodeAssociation[k] is a number of node type object in the
// node types array for the k-th node
nodeAssociation.assign(numOfNds, 0);
// 2 STEP:
// Creation base for BNet using Graph, types of nodes and nodes association
CBNet* pBNet = CBNet::Create( numOfNds, nodeTypes, nodeAssociation, pGraph );
// 3 STEP:
// Allocation space for all factors of the model
pBNet-&gt;AllocFactors();
// 4 STEP:
// Creation factors and attach their to model
//create raw data tables for CPDs
float table0[] = { 0.5f, 0.5f };
float table1[] = { 0.5f, 0.5f, 0.9f, 0.1f };
float table2[] = { 0.8f, 0.2f, 0.2f, 0.8f };
float table3[] = { 1.0f, 0.0f, 0.1f, 0.9f, 0.1f, 0.9f, 0.01f, 0.99f };
float* table[] = { table0, table1, table2, table3 };
int i;
for( i = 0; i &lt; numOfNds; ++i )
{
    pBNet-&gt;AllocFactor(i);
    CFactor* pFactor = pBNet-&gt;GetFactor(i);
    pFactor-&gt;AllocMatrix( table[i], matTable );
}
</pre>

<hr><h3><a name="ug_DGrM">Dynamic Graphical Models</a></h3>

<p>
<i>Dynamic Bayesian Network (DBN)</i> represents a directed graphical model of
stochastic processes that generalize <i>Hidden Markov models (HMMs)</i> and
<i>Kalman Filter models (KFMs)</i> by representing the hidden and the observed state in terms
of state variables, which can have complex interdependencies. DBN is defined by
the following characteristics:
<ul>
  <li>prior, or initial, network
  <li>transition network frequently named <i>two-slice temporal Bayesian Network (2TBN)</i>.
</ul>
Prior network determines distribution of probabilities for all variables at the
initial moment of time. 2TBN represents a two-slice Bayesian network whose first
layer nodes have no parameters associated with them and determine the system at
the previous moment of time while each second layer node has conditional
probabilities (<a href="#figDBNr"> Figure 2-2.</a>).
</p><p>
Nodes of the second slice can have parents both in that very same layer
(corresponding to time <i>t</i>), and in the layer that represents the previous moment.
Note, that the word "dynamic" does not mean that the network changes over time.
It only means that a dynamic process is modelled.
</p>

<hr><h4><a name="figDBNr"> Figure 2-2. Dynamic Bayesian Network<a></h4>
<img align=center src="fig/ugfig3.gif">

<p>
The semantics of the DBN can be defined by unrolling the 2TBN for T time slices.
The resulting joint probability distribution is defined by the formula:
</p>
<img align=center src="fig/ugfig4.gif">,
<p>
where <i>&pi;(x<sub>t</sub><sup>i</sup>)</i>  means parents of <i>i-th</i> node in <i>t-th</i> time-slice, <i>n</i> is the number of nodes.
</p>
<p>
The Dynamic Bayesian network is stored in terms of PNL in a similar way as the
Bayesian network. Suppose, the prior network consists of <i>n</i> nodes. Then the
network stored internally to represent the Dynamic Bayesian network will consist
of <i>2n</i> nodes. First <i>n</i> nodes are joined in one graph to represent the topology of
the prior network. Nodes with numbers starting with <i>n</i> to <i>2n-1</i> are joined in a
graph that represents the <i>i-th</i> slice, where <i>i &gt; 0.</i> The joint graph is formed by
the combination of the two layers (prior and the <i>i-th</i> layers). <a href="#figUnrolledDBNr"> Figure 2-3</a>
shows a Bayesian network constructed by unrolling in two
time-slices of a dynamic Bayesian network. Note, that it is always possible to
restore the prior and the transition networks.
</p>

<hr><h4><a name="figUnrolledDBNr"> Figure 2-3. Unrolled Bayesian Networks<a></h4>

<img align=center src="fig/ugfig8.gif">

<p>
A DBN is created in terms of PNL by the following routine:
</p>
<hr><h4><a name="exCreationDBN">Example 2-2. Creation of DBN</a></h4>
<pre>
Creation of DBN model
X0 -&gt;X1
|    |
v    v
Y0 -&gt;Y1
all nodes are discrete and binary
*/
//Create static model
const int nnodes = 4;//Number of nodes
// 1) First need to specify the graph structure of the model;
int numOfNeigh[] = {2, 2, 2, 2};
int neigh0[] = {1, 2};
int neigh1[] = {0, 3};
int neigh2[] = {0, 3};
int neigh3[] = {1, 2};
ENeighborType orient0[] = { ntChild, ntChild };
ENeighborType orient1[] = { ntParent, ntChild };
ENeighborType orient2[] = { ntParent, ntChild };
ENeighborType orient3[] = { ntParent, ntParent };
int *neigh[] = { neigh0, neigh1, neigh2, neigh3 };
ENeighborType *orient[] = { orient0, orient1, orient2, orient3 };
CGraph* pGraph = CGraph::Create( nnodes, numOfNeigh, neigh, orient);
// 2) Creation of the Model Domain.
nodeTypeVector variableTypes;
const int numNt = 1;//number of Node types (all nodes are discrete)
variableTypes.resize(numNt);
variableTypes[0].SetType(1, 2);
intVector variableAssociation;
variableAssociation.assign(nnodes, 0);
CModelDomain *pMD;
pMD = CModelDomain::Create( variableTypes, variableAssociation );
// 3) Creation static BNet with random matrices
CBNet *pBNet = CBNet::CreateWithRandomMatrices( pGraph, pMD );
// 4) Creation DBN
CDBN *pDBN = CDBN::Create( pBNet );
</pre>

<hr><h3><a name="ug_LIMID">Influence Diagrams</a></h3>

<p>Influence diagrams are compact representations of decision problems under uncertainty. We will observe diagrams of ‘no forgetting’, i.e. that values of observed variables and decisions that have been taken are remembered at all later times. Such diagrams we will call Influence Diagrams (ID). We will contrast them with LIMIDs (LImited Memory Influence Diagrams). </p>

<p><b>Example 1 (PIGS) </b></p>

<table width="100%" border="0" cellspacing="0" cellpadding="2">
 <tr>
  <td width="50"></td>
  <td>
	<p>A pig breeder is growing pigs for a period of four months and subsequently selling them. During this period the pig may or may not develop a certain disease. If the pig has the disease at the time when it must be sold, the pig must be sold for slaughtering and its expected market price is then 300 DKK (Danish kroner). If it is disease free, its expected market price as a breeding animal is 1000 DKK. </p>
	<p>Once a month, a veterinary doctor sees the pig and makes a test for presence of the disease. If the pig is ill, the test will indicate this with probability .80, and if the pig is healthy, the test will indicate this with probability .90. At each monthly visit, the doctor may or may not treat the pig for the disease by injecting a certain drug. The cost of an injection is 100 DKK.</p>
	<p>A pig has the disease in the first month with probability .10. A healthy pig develops the disease in the subsequent month with probability .20 without injection, whereas a healthy and treated pig develops the disease with probability .10, so the injection has some preventive effect. An untreated pig which is unhealthy will remain so in the subsequent month with probability .90, whereas the similar probability is .50 for an unhealthy pig which is treated. Thus spontaneous cure is possible but treatment is beneficial on average.</p>
  </td>
 </tr>
</table>

<p>The story now continues in two versions. In the traditional influence diagram (ID) version, the pig breeder will at all times know whether the pig has been treated earlier and also the previous test results. If we extend the story to continue for many months or to have weekly or daily examinations with potential injections associated, the complexity of finding an optimal treatment strategy becomes forbidding.</p>
<hr><h4>Figure 2-4. LIMID representation of the ID version of PIGS</h4>
<img src="LIMID_files\figure_1.gif">

<p>In the LIMID version of the story, the pig breeder does not keep individual records for his pigs and has to make his decision knowing only the test result for the given month and the age of the pig. The memory has been limited to the extreme of only remembering the present.</p>
<hr><h4>Figure 2-5. LIMID version of PIGS</h4>
<img src="LIMID_files\figure_2.gif">

<p>LIMIDs are represented by directed acyclic graphs (DAGs) with three types of nodes. Chance nodes, displayed as circles, represent random variables. Decision nodes, displayed as squares, correspond to alternative choices available to the decision maker. Finally value nodes, displayed as diamonds, represent additive components of the joint utility function. We assume that the joint utility of a configuration of the chance and decision variables can be represented as the sum of the local utility functions associated with the value nodes.</p>
<p>A LIMID can be viewed as a special type of Bayesian network, where the state of each decision variable is to be imposed from the decision maker to meet an optimization objective, and where the variables at the value nodes are completely determined from its parent configurations. A LIMID differs from a traditional ID representation of a decision problem in two ways:</p>
<ol>
  <li>The sequence in which decisions are to be taken is not specified other than through it being compatible with the partial order induced by the DAG, i.e. if d2 is a descendant of _the d1 decision d1 must be taken before d2 . </li>
  <li>The parents of a decision node d represent exactly the variables whose values are known and taken into consideration when d is to be taken. In traditional IDs, this relation is more complicated and varies somewhat between authors. </li>
</ol>
<p>Thus, LIMIDs allow for multiple or forgetful decision makers.</p>

<hr><h4>Example 2-3. Creation of "PIGS" LIMID</h4>
<p>Consider the following network:</p>
<img src="model.gif">
<p>In this picture circles describe chance nodes. Each chance node has it’s probability distribution, which is shown near circles.</p>
<p>Squares describe decision nodes. We want to find out probability distributions for this nodes. That is why fields near the nodes are lived blank.</p>
<p>Diamonds describe utility nodes and the tables near the nodes show the distribution of the income.</p>
<p>To load this model you may use the following function:</p>

<pre>
CIDNet* CreatePigsLIMID()
{
    const int nnodes = 14;
    const int numberOfNodeTypes = 14;

    int i;

    CGraph *pGraph = CGraph::Create(0, NULL, NULL, NULL);
    pGraph->AddNodes(nnodes);
    pGraph->AddEdge(0,1,1);
    pGraph->AddEdge(0,3,1);
    pGraph->AddEdge(1,2,1);
    pGraph->AddEdge(2,3,1);
    pGraph->AddEdge(3,4,1);
    pGraph->AddEdge(3,6,1);
    pGraph->AddEdge(4,5,1);
    pGraph->AddEdge(5,6,1);
    pGraph->AddEdge(6,7,1);
    pGraph->AddEdge(6,9,1);
    pGraph->AddEdge(7,8,1);
    pGraph->AddEdge(8,9,1);
    pGraph->AddEdge(2,10,1);
    pGraph->AddEdge(5,11,1);
    pGraph->AddEdge(8,12,1);
    pGraph->AddEdge(9,13,1);

    CNodeType *nodeTypes = new CNodeType [numberOfNodeTypes];

    nodeTypes[0].SetType(1, 2, nsChance);
    nodeTypes[1].SetType(1, 2, nsChance);
    nodeTypes[2].SetType(1, 2, nsDecision);
    nodeTypes[3].SetType(1, 2, nsChance);
    nodeTypes[4].SetType(1, 2, nsChance);
    nodeTypes[5].SetType(1, 2, nsDecision);
    nodeTypes[6].SetType(1, 2, nsChance);
    nodeTypes[7].SetType(1, 2, nsChance);
    nodeTypes[8].SetType(1, 2, nsDecision);
    nodeTypes[9].SetType(1, 2, nsChance);
    nodeTypes[10].SetType(1, 1, nsValue);
    nodeTypes[11].SetType(1, 1, nsValue);
    nodeTypes[12].SetType(1, 1, nsValue);
    nodeTypes[13].SetType(1, 1, nsValue);

    int *nodeAssociation = new int[nnodes];
    for ( i = 0; i < nnodes; i++ )
    {
      nodeAssociation[i] = i;
    }

    CIDNet *pIDNet = CIDNet::Create( nnodes, numberOfNodeTypes, nodeTypes,
    nodeAssociation, pGraph );

    CModelDomain* pMD = pIDNet->GetModelDomain();
    
//number of parameters is the same as number of nodes - one CPD per node   
    CFactor **myParams = new CFactor*[nnodes];
    int *nodeNumbers = new int [nnodes];
    
    int domain0[] = { 0 };
    nodeNumbers[0] =  1;
    int domain1[] = { 0, 1 };
    nodeNumbers[1] =  2;
    int domain2[] = { 1, 2 };
    nodeNumbers[2] =  2;
    int domain3[] = { 2, 10 };
    nodeNumbers[3] =  2;
    int domain4[] = { 0, 2, 3 };
    nodeNumbers[4] =  3;
    int domain5[] = { 3, 4 };
    nodeNumbers[5] =  2;
    int domain6[] = { 4, 5 };
    nodeNumbers[6] =  2;
    int domain7[] = { 5, 11 };
    nodeNumbers[7] =  2;
    int domain8[] = { 3, 5, 6 };
    nodeNumbers[8] =  3;
    int domain9[] = { 6, 7 };
    nodeNumbers[9] =  2;
    int domain10[] = { 7, 8 };
    nodeNumbers[10] =  2;
    int domain11[] = { 8, 12 };
    nodeNumbers[11] =  2;
    int domain12[] = { 6, 8, 9 };
    nodeNumbers[12] =  3;
    int domain13[] = { 9, 13 };
    nodeNumbers[13] =  2;

    int *domains[] = { domain0, domain1, domain2, domain3, domain4,
    domain5, domain6, domain7, domain8, domain9, domain10, domain11, 
    domain12, domain13 };

    pIDNet->AllocFactors();

    for( i = 0; i < nnodes; i++ )
    {
      myParams[i] = CTabularCPD::Create( domains[i], nodeNumbers[i], pMD);
    }
    
// data creation for all CPDs of the model    
    float data0[] = {0.9f, 0.1f};
    float data1[] = {0.1f, 0.9f, 0.8f, 0.2f};
    float data2[] = {0.5f, 0.5f, 0.5f, 0.5f};
    float data3[] = {-100.0f, 0.000000f};
    float data4[] = {0.9f, 0.1f, 0.8f, 0.2f, 0.5f, 0.5f, 0.1f, 0.9f};
    float data5[] = {0.1f, 0.9f, 0.8f, 0.2f};
    float data6[] = {0.5f, 0.5f, 0.5f, 0.5f};
    float data7[] = {-100.0f, 0.0f};
    float data8[] = {0.9f, 0.1f, 0.8f, 0.2f, 0.5f, 0.5f, 0.1f, 0.9f};
    float data9[] = {0.1f, 0.9f, 0.8f, 0.2f};
    float data10[] = {0.5f, 0.5f, 0.5f, 0.5f};
    float data11[] = {-100.0f, 0.0f};
    float data12[] = {0.9f, 0.1f, 0.8f, 0.2f, 0.5f, 0.5f, 0.1f, 0.9f};
    float data13[] = {1000.0f, 300.0f};

    float *data[] = { data0, data1, data2, data3, data4,
                      data5, data6, data7, data8, data9,
                      data10, data11, data12, data13 };

    for( i = 0; i < nnodes; i++ )
    {
        myParams[i]->AllocMatrix(data[i], matTable);
        pIDNet->AttachFactor(myParams[i]);
    }

    delete [] nodeTypes;
    delete [] nodeAssociation;

    return pIDNet;
}
</pre>

<hr><h3><a name="ug_Diagnostics">Diagnostic Networks</a></h3>
<p>Diagnosis is the process of identifying the disease or disorder of a patient or a machine by considering its history of symptoms and other signs. In general, diagnostics includes two types of problems. The first task is to determine the true cause or when multiple causes may occur simultaneously the combination of true causes. The second task is to reduce the uncertainty about the true cause by obtaining more information about the state of the world. Possible information sources are symptoms, results of tests, or historic data. Using this information several assumptions are made: </p>
<ul>
<li>The information is perfect, i.e., there is no possibility that the information is either wrong or incomplete.</li>
<li>The information never increases uncertainty. </li>
</ul>
<p>Now for supporting diagnostics you can use Bayesian networks. All nodes in Bayesian network can be divided into 3 groups: </p>
<ul>
<li>Target nodes (hypothesis variable) - each hypothesis state of hypothesis variable may represent a possible disease, fault in a system, or any other discomfort. </li>
<li>Observation nodes (test variable)- each test state of test variable may represent an observation, physical sign, indicant, symptom or laboratory result. </li>
<li>Other. </li>
</ul>
<p>For performance of diagnostics the network should have a minimum one target node and minimum one test node. For each test node it is necessary to set cost of carrying out of the test. </p>
<table width = "100%">
	<tr><td><p>The algorithm of diagnostics consists in calculating a priority of performing a tests for reduction of uncertainty of the diagnosis. For that it is necessary to define a list of target nodes.
The following algorithm solves that problem. The input parameters are:
    <ul type=disc>
	<li>The list of target nodes for which it is necessary to reduce uncertainty.
	<li>The list of target states for these nodes.
	</ul>
At the output parameter is the list of test nodes in ascending order.
Because small and large joint probabilities are only possible when the marginal probabilities are either small or large. 
Generally it is necessary to estimate benefit of performing each set of test nodes. We suppose that only one test is available now because in the other case it`s computational impracticable problem. Benefit of performing a test is estimated by the following formula: 
 <img src="formulas\Ts_eb_ev.gif" align="left" >
 <br><br><p>&nbsp;<p>, where K is a parameter set by user, 
<br>Cost(T) is cost of performing a test (observation) T. 
<br>V(Pr(H)) is a value function. 
<br><br><br><br> <p>&nbsp;<p><tr><td> In PNL library two diferent value functions are realized.
<br> <img src="formulas\MS1 & MS2.gif" align="left" width="528" height="345">
<br><br><br><br><br><br><br><p>&nbsp;<p>, where F is set of target nodes.
    </td></tr>
    </td></tr>
</table>

<hr><h4>Example 2-4. Diagnostics with Bayesian networks</h4>
<p>Consider the following network:</p>
<img src="LIMID_files\asia.gif">
		To start diagnostics with this network you may use the following source code.
		<pre>
int main(int argc, char* argv[])
{
<font color="green">/*---- Network creation -----------------------------------------------------*/</font>
    const CBNet* pBNet;
    pBNet = pnlExCreateAsiaBNet();  <font color="green"> // load standart model example </font>

<font color="green">/*---- Diagnostics creation -------------------------------------------------*/</font>
    CDiagnostics *pDiag = CDiagnostics::Create(pBNet);
    pDiag->SetCostRatio(1); <font color="green">         // set parameter for VOI function</font>

<font color="green">/*---- Setting of target nodes ----------------------------------------------*/</font>
    intVector tarN;
    tarN.push_back(2);
    tarN.push_back(3);
    tarN.push_back(4);
    pDiag->SetTargetNodes(tarN);

<font color="green">/*---- Setting of test nodes ------------------------------------------------*/</font>
    intVector testN;
    testN.push_back(0);
    testN.push_back(1);
    testN.push_back(6);
    testN.push_back(7);
    pDiag->SetObservationNodes(testN);
    pDiag->SetCost(0,1);             <font color="green">// set cost of observation for 0 node</font>
    pDiag->SetCost(1,1);             <font color="green">// set cost of observation for 1 node</font>

<font color="green">/*---- Setting of target states ---------------------------------------------*/</font>
    pDiag->SetTargetState(2,1);
    pDiag->SetTargetState(3,1);
    pDiag->SetTargetState(4,1);

<font color="green">/*---- Choosing of selecting function ---------------------------------------*/</font>
    pDiag->SetAlgorithm(0); 

<font color="green">/*---- Vector of pursued node creation --------------------------------------*/</font>
    intVector purN;
    purN.push_back(2);
    purN.push_back(3);
    purN.push_back(4);
    intVector purS;
    purS.push_back(1);
    purS.push_back(1);
    purS.push_back(1);
<font color="green">/*---- Diagnostics execution ------------------------------------------------*/</font>
    intVector resVOI, resTests;
    resVOI.resize(0);
    resTests.resize(0); 
    pDiag->GetTestsList(purN, purS, resTests, resVOI);
<font color="green">/*---- Result output --------------------------------------------------------*/</font>
    int i;
    for( i = 0; i < resVOI.size(); ++i )
    {
        printf("%d\t%d\n", resTests[i],resVOI[i]);
    }
    return 0;
}
</pre>

<hr><h3><a name="ug_Inf">Inference Algorithms for Bayesian and Markov Networks</a></h3>

<p>
The inference problem in the context of a graphical model is equivalent to the
estimation of joint probability distribution, also called marginal distribution
or simply marginal, of one or several nodes without evidence or with a limited
number of observed nodes:
</p>

<i>P ( x<sub>q1</sub> , x<sub>q2</sub> , ... x<sub>qk</sub> | x<sub>e1</sub> , x<sub>e2</sub> ,... x<sub>es</sub> ) = P ( X<sub>q</sub> | X<sub>e</sub> ),</i>
<p>
where <i>e</i> denotes the evidences or observed nodes, and <i>q</i> denotes the query nodes
whose distribution is to be calculated.
</p>
<p>
This problem has several solutions. The most evident of them is the direct
computation of joint probability distribution for all nodes of the graphical
model followed by calculation of probability distribution for the query nodes
using Bayes equation:
</p>

<img align=center src="fig/ugfig9.gif">

<p>
This joint probability distribution can be found through multiplication of all
conditional probability distributions of a Bayesian network or of all joint
probability distributions at the cliques of the Markov network. Before
multiplication these conditional and unconditional distributions should be
adjusted to the values of observed nodes of the network. The final step is to
sum up the resulting values. This description fully applies to the <tt>CNaiveInfEngine.</tt>
See Creation of inference engine for water srinkler BNet of call of such
inference engine for the "water-sprinkler" model (<a href="#exInfWS">Example 2-5</a>).
</p>

<hr><h4><a name="exInfWS">Example 2-5. Creation of inference engine for water srinkler BNet</a></h4>

<pre>
//create Water - Sprinkler BNet
CBNet* pWSBnet =
pnlExCreateWaterSprinklerBNet();//CreateWaterSprinklerBNet();
//get content of Graph
pWSBnet-&gt;GetGraph()-&gt;Dump();
//create simple evidence for node 0 from BNet
CEvidence* pEvidForWS;
//make one node observed
int nObsNds = 1;
//the observed node is 0
int obsNds[] = { 0 };
//node 0 takes its second value (from two possible values {0, 1})
valueVector obsVals;
obsVals.resize(1);
obsVals[0].SetInt(1);
pEvidForWS = CEvidence::Create( pWSBnet, nObsNds, obsNds, obsVals );
//create Naive inference for BNet
CNaiveInfEngine* pNaiveInf = CNaiveInfEngine::Create( pWSBnet );
//enter evidence created before
pNaiveInf-&gt;EnterEvidence( pEvidForWS );
//get a marginal for query set of nodes
int numQueryNds = 2;
int queryNds[] = { 1, 3 };
pNaiveInf-&gt;MarginalNodes( queryNds, numQueryNds );
const CPotential* pMarg = pNaiveInf-&gt;GetQueryJPD();
intVector obsNds;
pConstValueVector obsVls;
pEvidForWS-&gt;GetObsNodesWithValues(&amp;obsNds, &amp;obsVls);
int i;
for( i = 0; i &lt; obsNds.size(); i++ )
{
    std::cout&lt;&lt;" observed value for node "&lt;&lt;obsNds[i];
    std::cout&lt;&lt;" is "&lt;&lt;obsVls[i]-&gt;GetInt()&lt;&lt;std::endl;
}
int nnodes;
const int* domain;
pMarg-&gt;GetDomain( &amp;nnodes, &amp;domain );
std::cout&lt;&lt;" inference results: \n";
std::cout&lt;&lt;" probability distribution for nodes [ ";
for( i = 0; i &lt; nnodes; i++ )
{
    std::cout &lt;&lt;domain[i] &lt;&lt;" ";
}
std::cout&lt;&lt;"]"&lt;&lt;std::endl;
CMatrix&lt;float&gt;* pMat = pMarg-&gt;GetMatrix(matTable);
// graphical model hase been created using dense matrix
// so, the marginal is also dense
EMatrixClass type = pMat-&gt;GetMatrixClass();
if( ! ( type == mcDense || type == mcNumericDense || type == mc2DNumericDense ) )
{
    assert(0);
}
int nEl;
const float* data;
static_cast&gt;CNumericDenseMatrix&lt;float&gt;*&gt;(pMat)-&gt;GetRawData(&amp;nEl, &amp;data);
for( i = 0; i &gt; nEl; i++ )
{
    std::cout&lt;&ltl;" "&lt;&lt;data[i];
}
std::cout&lt;&lt;std::endl;
delete pEvidForWS;
delete pNaiveInf;
delete pWSBnet;
</pre>
<p>
However, the direct computation is too laborious, as the complexity of
computations grows exponentially with the number of nodes in a network. This
type of computation appears to be ineffective even for small models and is
seldom used in practice.
</p><p>
To reduce the complexity of computations, you may use the distribution law.
Since in certain areas of the network local distributions are independent of
variables,you can apply the distribution law to calculate distributions for
query nodes. So, for example, the probability distribution for the
"water-sprinkler" problem at node 3, which has no observed variables, is
expanded as follows:
</p>

<img align=center src="fig/ugfig10.gif"><br>
<img align=center src="fig/ugfig11.gif">

<p>
A number of exact and approximate inference engines are based on the use of the
distribution law.
</p>
<p>
Initially each component of the network, be it a single node or a group of
nodes, is assigned a certain distribution function, which represents assumed
node values of the network. In the course of iterative message passing between
neighboring components of the network the distribution function is modified. So,
two components can be neighbors in terms of one inference engine and
non-neighbors in terms of another. The sequence of message passing, often called
a protocol, can also be different: from one component to all the others and back
(tree protocol, or serial protocol) or all-to-all simultaneous message passing
(parallel protocol).
</p><p>
If a graph of a Bayesian or a Markov network is a tree, most obvious network
components are nodes. Neighboring nodes in the graph are also neighbors in the
network. In this case you use the exact <i>Pearl Inference</i> or <i>Belief Propagation.</i>
If the graph contains undirected cycles, you can assume nodes as network
components and get an approximate result. To get a more accurate result, you
should increase the number of iterations and use, for example, the algorithm of
Loopy Belief Propagation. In certain cases it does not converges or converges to
a local minimum <a href="openpnl_bibliography.htm#ref_MWJ">[ MWJ ]</a>, <a href="openpnl_bibliography.htm#ref_H">[ H ]</a>, yet it has proven to be exact on acyclic
networks <a href="openpnl_bibliography.htm#ref_P1">[ P1 ]</a>. A lot of research is being carried out at present on the
adaptability of Belief Propagation to networks of various types (<a href="openpnl_bibliography.htm#ref_WF2000">[ WF2000 ]</a>,<a href="openpnl_bibliography.htm#ref_WF2001">[ WF2001 ]</a>).
</p><p>
Inference engines of different types are created in the same manner:<br>
<blockquote>
  <tt>InfEngine = CPearlInfEngineCreate( grm );</tt>
</blockquote>
</p>
<p>
As the sample model contains an undirected cycle (through nodes 0, 1, 2, and 3)
any inferred result is approximate.
</p>
<p>
To infer the exact result on an arbitrary network, nodes of the network are
grouped into subsets, or clusters, which are set in accordance with the nodes of
an auxiliary junction tree structure. Message passing in this case takes place
between the nodes of this junction tree. This procedure is called
<i>Junction Tree Inference</i>, which is exact <a href="openpnl_bibliography.htm#ref_LS">[ LS ]</a>, <a href="openpnl_bibliography.htm#ref_CDLS">[ CDLS ]</a>.
</p>

<hr><h3><a name="ug_PBInf">Particle-based Inference</a></h3>

<p>
Besides exact inference engines, for example, the Junction Tree Inference, there
is an important class of <i>particle-based inference</i> methods. To approximate the
joint distribution either of all or of a number of the network variables, the
method generates a set of approximations, called <i>particles</i>, that represent a
part of the probability mass. Particle-based approximate inference engine can
calculate query potentials and estimate real states of query nodes. Commonly
used particle-based method is <i>GibbsSampling.</i>
</p>

<hr><h3><a name="ug_InfDBN">Inference Algorithms for DBNs</a></h3>

<p>
The inference problem in the context of a dynamic graphical model is equivalent
to the marginal estimation of one or several nodes from a number of slices
irrespective of whether the nodes are observed or hidden. It is implemented
through the following computation <nobr><i>P(x(i, t)|y(:, t<sub>1</sub>:t<sub>2</sub>))</i>,</nobr>
where <i>x(i, t)</i>  represents the <i>i-th</i> hidden variable
at time moment <i>t</i>, and <i>t</i> and <nobr><i>y(:, t<sub>1</sub>:t<sub>2</sub>)</i></nobr>
represent all the evidence between times <nobr><i>t<sub>1</sub></i> and <i>t<sub>2</sub>.</i></nobr>
The algorithm often performs computation of joint probability distributions
of variables over one or more time slices.
</p>

<TABLE BORDER>
<CAPTION><b>Types of Inference Problems for DBNs</b></CAPTION>
<TR>
<TH>Procedure</TH>
<TH>Goal</TH>
</TR><TR>
<TD>Filtering</TD>
<TD><i>P(x(t)|y(1:t))</i><br>
On-line procedure to estimate current model state.</TD>
</TR><TR>
<TD>Smoothing</TD>
<TD><i>P(x(1:t)|y(1:t))</i><br>
Off-line procedure to estimate the states of the past, given all evidence up to the current time t.</TD>
</TR><TR>
<TD> Fixed-Lag Smoothing</TD>
<TD><i>P(x(t-dt)|y(1:t))</i><br>
On-line procedure to estimate the state of some past moment (t-dt), given
all evidence up to the current time t.</TD>
</TR><TR>
<TD>Viterbi</TD>
<TD><i>max<sub>x(1:t)</sub>P(x(t)|y(1:t))</i><br>
Off-line procedure to compute the most likely sequence of hidden states,
given the data.</TD>
</TR><TR>
<TD>Prediction</TD>
<TD><i>P(x(t+dt)|y(1:t))</i><br>
On-line procedure that extrapolates probability distribution for future
time slices.</TD>
</TR>
</TABLE>
<p>
Note that filtering is equivalent to fixed-lag smoothing with zero lag.
</p><p>
Inference procedure can be implemented through various approaches, some of which
are naïve as those that follow:
<ul>
  <li>combine all the latent nodes from a single layer into a single meganode and
  apply the forward-backward algorithm for HMM, if the nodes are discrete.</li>
  <li>unroll DBN and do inference, for example Junction Tree or Pearl Inference, for
  the BNet obtained as a result of unroll operation.</li>
</ul>
To compute statistics which are used to learn parameter values, you call
inference (smoothing) for a BNet which is as long as the sequence of evidence.
If sequences of evidences are of variable lengths, junction trees (for the
Junction Tree Inference) should be constructed many times, which considearbly
slows down the process, or precomputed and stored for all possible unrolled DBN,
which requires a lot of memory. Hence, it is necessary to use a DBN with
repeating structure. One of the algorithms that uses repeating structures of
DBNs is Zweig's inference algorithm. The algorithm unrolls a DBN once to some
<i>T<sub>max</sub></i> slices, creates a junction tree and splices out extra cliques from it, when
<i>t &lt; T<sub>max</sub></i> . But <i>T<sub>max</sub></i> should be preliminarily specified for the inference, and
online inference can be performed for this maximum number of slices. PNL
implements 1.5-slice Junction tree inference algorithm <a href="openpnl_bibliography.htm#ref_Murphy02">[ Murphy02 ]</a>. This
approach involves the following steps:
<ol>
  <li> Create a 1.5-slice DBN - one time slice of DBN plus interface nodes from the
  previous slice. Interface nodes are the nodes connected with the nodes from the
  next slice and they are always the same for all time slices.</li>
  <li> Create a junction tree for the obtained network.</li>
  <li> Link up all the junction trees via interfaces.</li>
</ol>
</p><p>
This algorithm can perform on-line inference with no preliminarily specified T
max. Inference procedure consists of two steps, which are the forward and the
backward operation. They are the same as the steps in the classical inference
algorithm for HMM. See <a href="#exInfDNM">Example 2-6.</a>
</p></p>
Besides exact inferences described above there are different variants of
approximate inferences. One of them is the Boyen-Koller inference (BK). BK
inference is the approximate inference in which the belief state of the
interface clique (clique consists of interface nodes and is used for message
passing between slices in 1.5 Slice Junction tree inference) is represented as a
product of marginals, even though the factors may be dependent. For details, see
[BKUAI98] and [BKNIPS98] , which discuss filtering and smoothing respectively.
Note that the exact 1.5 Slice Junction tree inference is the special case of BK
inference.
</p>

<hr><h4><a name="exInfDNM">Example 2-6. Creation of inference engine for DBN</a></h4>

<pre>
CBNet *pBNetForArHMM = pnlExCreateRndArHMM();
CDBN *pArHMM = CDBN::Create( pBNetForArHMM );
//Create an inference engine
C1_5SliceJtreeInfEngine* pInfEng;
pInfEng = C1_5SliceJtreeInfEngine::Create(pArHMM);
//Number of time slices for unrolling
int nTimeSlices = 5;
const CPotential* pQueryJPD;
//Create evidence for every slice
CEvidence** pEvidences;
pEvidences = new CEvidence*[nTimeSlices];
//Let node 1 is always observed
const int obsNodesNums[] = { 1 };
valueVector obsNodesVals(1);
int i;
for( i = 0; i &lt; nTimeSlices; i++ )
{
    // Generate random value
    // all nodes in the model are discrete
    obsNodesVals[0].SetInt(rand()%2);
    pEvidences[i] = CEvidence::Create( pArHMM, 1, obsNodesNums,
    obsNodesVals );
}
// Create smoothing procedure
pInfEng-&gt;DefineProcedure(ptSmoothing, nTimeSlices);
// Enter created evidences
pInfEng-&gt;EnterEvidence(pEvidences, nTimeSlices);
// Start smoothing process
pInfEng-&gt;Smoothing();
// Choose query set of nodes for every slice
int queryPrior[] = { 0 };
int queryPriorSize = 1;
int query[] = { 0, 2 };
int querySize = 2;
// inference results gaining and representation
std::cout &lt;&lt; " Results of smoothing " &lt;&lt; std::endl;
int slice = 0;
pInfEng-&gt;MarginalNodes( queryPrior, queryPriorSize, slice );
pQueryJPD = pInfEng-&gt;GetQueryJPD();
std::cout&lt;&lt;"Query slice"&lt;&lt;slice&lt;&lt;std::endl;
int nnodes;
const int* domain;
pQueryJPD-&gt;GetDomain( &amp;nnodes, &amp;domain );
std::cout&lt;&lt;" domain :";
for( i = 0; i &lt; nnodes; i++ )
{
    std::cout&lt;&lt;domain[i]&lt;&lt;" ";
}
std::cout&lt;&lt;std::endl;
CMatrix&lt;float&gt;* pMat = pQueryJPD-&gt;GetMatrix(matTable);
// graphical model hase been created using dense matrix
std::cout&lt;&lt;" probability distribution \n";
int nEl;
const float* data;
static_cast&lt;CNumericDenseMatrix&lt;float&gt;*&gt;(pMat)-&gt;GetRawData(&amp;nEl,&amp;data);
for( i = 0; i &lt; nEl; i++ )
{
    std::cout&lt;&lt;" "&lt;&lt;data[i];
}
std::cout &lt;&lt; std::endl;
for( slice = 1; slice &lt; nTimeSlices; slice++ )
{
    pInfEng-&gt;MarginalNodes( query, querySize, slice );
    pQueryJPD = pInfEng-&gt;GetQueryJPD();
    std::cout&lt;&lt;"Query slice"&lt;&lt;slice&lt;&lt;std::endl;
    // Representation information using Dump()
    pQueryJPD-&gt;Dump();
}
slice = 0;
//Create filtering procedure
pInfEng-&gt;DefineProcedure( ptFiltering );
pInfEng-&gt;EnterEvidence( &amp;(pEvidences[slice]), 1 );
pInfEng-&gt;Filtering( slice );
pInfEng-&gt;MarginalNodes( queryPrior, queryPriorSize );
pQueryJPD = pInfEng-&gt;GetQueryJPD();
std::cout&lt;&lt;" Results of filtering " &lt;&lt; std::endl;
std::cout&lt;&lt;" Query slice "&lt;&lt;slice&lt;&lt;std::endl;
pQueryJPD-&gt;Dump();
for( slice = 1; slice &lt; nTimeSlices; slice++ )
{
    pInfEng-&gt;EnterEvidence( &amp;(pEvidences[slice]), 1 );
    pInfEng-&gt;Filtering( slice );
    pInfEng-&gt;MarginalNodes( query, querySize );
    pQueryJPD = pInfEng-&gt;GetQueryJPD();
    std::cout&lt;&lt;" Query slice "&lt;&lt;slice&lt;&lt;std::endl;
    pQueryJPD-&gt;Dump();
}
//create prediction procedure (it is used only after filtering)
int delta = 2;
pInfEng-&gt;Prediction(delta);
// in prediction procedure query must contain only nodes with numbers n...2n - 1. 
// in our example query must be equal {1} or {1,2} or {2} 
pInfEng-&gt;MarginalNodes( query, querySize, nTimeSlices + delta);
pQueryJPD = pInfEng-&gt;GetQueryJPD();
std::cout&lt;&lt;" Query slice "&lt;&lt;(slice + delta)&lt;&lt;std::endl;
pQueryJPD-&gt;Dump();
 
//Create fixed-lag smoothing (online)
int lag = 2;
pInfEng-&gt;DefineProcedure( ptFixLagSmoothing, lag );
for (slice = 0; slice &lt; lag + 1; slice++)
{
    pInfEng-&gt;EnterEvidence( &amp;(pEvidences[slice]), 1 );
}
pInfEng-&gt;FixLagSmoothing( slice );
pInfEng-&gt;MarginalNodes( queryPrior, queryPriorSize );
pQueryJPD = pInfEng-&gt;GetQueryJPD();
std::cout&lt;&lt;" Results of fixed-lag smoothing " &lt;&lt; std::endl;
std::cout&lt;&lt;" Query slice "&lt;&lt;slice&lt;&lt;std::endl;
pQueryJPD-&gt;Dump();
std::cout &lt;&lt; std::endl;
for( ; slice &lt; nTimeSlices; slice++ )
{
    pInfEng-&gt;EnterEvidence( &amp;(pEvidences[slice]), 1 );
    pInfEng-&gt;FixLagSmoothing( slice );
    pInfEng-&gt;MarginalNodes( query, querySize );
    pQueryJPD = pInfEng-&gt;GetQueryJPD();
    std::cout&lt;&lt;" Query slice "&lt;&lt;slice&lt;&lt;std::endl;
    pQueryJPD-&gt;Dump();
}
delete pInfEng;
for( slice = 0; slice &lt; nTimeSlices; slice++)
{
    delete pEvidences[slice];
}
delete pArHMM;

</pre>
<p>
The dynamic bayesian network is created by a BNet with <i>2n</i> nodes, that is a DBN,
unrolled in two slices. Nodes with numbers from <i>0</i> to <i>n-1</i> form a connected graph
corresponding to the prior slice. The topology of the prior slice may differ
from the topology of other slices with node numbers from <i>n</i> to <i>2n-1.</i>
Evidence of every slice with n nodes is formed from nodes with numbers from <i>0</i> to
<i>n-1.</i>
</p><p>
To get inference results, the query for the prior slice (slice = 0) should
contain nodes with numbers from <i>0</i> to <i>n-1.</i> Probability distribution for other
slices is acquired from the current <i>i-th</i> slice and the preceding slice <i>i-1.</i> In
this query node numbers <i>n...2n-1</i> correspond to the nodes of the current slice,
while node numbers <i>0...n-1</i> correspond to the nodes of the preceding slice.
</p>

<hr><h3><a name="ug_InfLIMID">Inference Algorithms for LIMIDs</a></h3>
<table width = "100%">
	<tr><td><p><h4>Policies and strategies</h4></p>
		<p>A pure policy for decision node <i>d</i> prescribes an alternative in the set of all possible values for each possible configuration of its parents <i>pa(d)</i>.The designation for a node <i>d</i> policy is <img src="formulas/1.gif">.  To allow for possible randomization we consider more general policies represented by functions on the set of all possible values of node <i>d</i> and set of all possible configurations of it’s parents <i>pa(d)</i> Cartesian product. This function represent a probability distribution over alternative choices of d  for each possible configuration of <i>pa(d)</i>.</p>
		<p>A <i>strategy</i> for a LIMID is a set of policies for each decision node. A pure strategy is a set of pure policies. If a strategy is not pure it is called <i>random</i>.</p>
		<p>A <i>global maximum strategy Q</i> is a strategy which satisfies <i>E(U(Q)) >= E(U(q))</i> for all strategies <i>q</i>.</p>
		<p>If our main goal is to maximize the mathematical expectation of the income, we have to find a strategy which satisfies <i>E(U(Q)) >= E(U(q))</i> for all strategies <i>q</i>. </p>
		<p><h4>Local maximum strategy and income expectation</h4></p>
		<p>For each strategy <img src="formulas/2.gif"> and any decision node <i>d0</i> we will define <img src="formulas/3.gif">. Now let <img src="formulas/4.gif"> (we simply changed policy <img src="formulas/5.gif"> to policy <img src="formulas/6.gif">)</p>
		<p>A <i>local maximum policy</i> for a strategy <i>q</i> at <i>d</i> decision node is a policy <img src="formulas/7.gif"> which satisfies</p>
		<p><img src="formulas/8.gif"></p>
		<p>A strategy <img src="formulas/9.gif"> is said to be a local maximum strategy if all its policies are local maximum policies, i.e. if for all decision nodes <i>d</i> and all policies <img src="formulas/1.gif"> we have <img src="formulas/10.gif">.</p>
		<p><h4>Single policy updating</h4></p>
		<p>This subsection describes an iterative procedure for improving strategies within LIMIDs termed <i>Single Policy Updating (SPU)</i>. From an initial strategy <i>q<sup>0</sup></i>  it updates each policy in some order.</p>
		<p>Assume that the current strategy is <i>q<sup>l</sup></i> and that the policy for <i>d<sub>0</sub></i> is to be updated. Then the next strategy <i>q<sup>l+1</sup></i> only differs from <i>q<sup>l</sup></i> on the policy for <i>d<sub>0</sub></i> and it is generated by finding a local maximum policy <img src="formulas/11.gif"> for <i>q<sup>l</sup></i> and <i>d<sub>0</sub></i> at and letting <img src="formulas/12.gif">.</p>
		<p>When all the policies have been updated once we say that one <i>cycle</i> has been performed. The algorithm stops if the expected utility of strategies generated in two successive cycles is unaltered.</p>
		<p>A few comments are in place here:</p>
		<ul>
			<li>The initial strategy <i>q<sup>0</sup></i>  may be random and it is typically advantageous to choose it as such</li>
			<li>There is always a pure local maximum policy <img src="formulas/11.gif">, however it may not be unique.</li>
		</ul>
		<p>If we always choose a pure local maximum policy in each step, the algorithm eventually reaches a local maximum strategy at which no progress is made. This holds because there is only a finite number of pure strategies and the expected utility increases at each cycle. These observations are stated formally below.</p>
		<p><b>Iterative improvement</b><i> SPU is an iterative improvement algorithm: after each cycle, the expected utility of the current strategy has increased or is unaltered. In the latter case, the algorithm has reached a local maximum strategy.</i></p>
		<p><b>Convergence</b><i> SPU converges to a local maximum strategy if we always choose a pure policy in each updating step. In this case the algorithm converges in a finite number of cycles.</i></p>	
		<p>We shall later discuss how to choose initial strategies, updating sequences, and give conditions ensuring local maximum strategies to be global maximum strategies.</p>
		<p><h4>Potentials and their operations</h4></p>
		<p>In our local computation algorithms we represent the quantitative elements of a LIMID through entities called potentials. Each such potential has two parts as detailed below.</p>
		<p>Let <i>W</i> be a subset of chance and decision nodes. Then a Potential on <i>W</i> is a pair <img src="formulas/13.gif"> of real-valued functions on the set of all values of nodes from set <i>W</i>,  and <i>p<sub>w</sub></i> is non-negative.</p>
		<p>The first part <i>p<sub>w</sub></i> of the potential is called the <i>probability part</i>, and the second part <i>u<sub>w</sub></i> is called the <i>utility part</i>. We call the probability part vacuous if it is equal to unity, and the utility part is vacuous if it is identically equal to zero.</p>
		<p>We identity two potentials <img src="formulas/14.gif"> and <img src="formulas/15.gif"> on <i>W</i> and write <img src="formulas/16.gif"> if <img src="formulas/17.gif"> and <img src="formulas/18.gif"> whenever <img src="formulas/19.gif">, i.e. two potentials are considered equal if they have identical probability parts and their utility parts agree almost surely with respect to the probability parts.</p>
		<p>Let <img src="formulas/20.gif"> and <img src="formulas/21.gif"> be two potentials on <i>W<sub>1</sub></i> and <i>W<sub>2</sub></i> respectively. The combination <img src="formulas/22.gif"> of <img src="formulas/23.gif"> and <img src="formulas/24.gif"> is the potential on <img src="formulas/25.gif"> given by</p>
		<p><img src="formulas/26.gif"></p>
		<p>Let <img src="formulas/13.gif"> be a potential on <i>W</i>, and let <img src="formulas/27.gif">. The marginalization <img src="formulas/28.gif"> of <img src="formulas/29.gif"> onto <i>W<sub>1</sub></i>  is the potential on <i>W<sub>1</sub></i> given by </p>
		<p><img src="formulas/30.gif"></p>
		<p>The division operation in the utility part is necessary to preserve expected utilities. The convention 0/0=0  has been used here and throughout.</p>
		<p><h4>Inference engine based on Junction tree</h4></p>
		<p>As mentioned, our algorithm proceeds by message passing in a suitable computational structure known as a junction tree. In the present subsection we describe how to construct this junction tree.</p>
		<p>As for similar local computation algorithms the construction involves first a moralization process, in which an undirected graph is constructed, then a triangulation, where additional edges are added, and finally the organization of the cliques of the triangulated graph into a junction tree.</p>
		<p>The transformation from the LIMID <i>L</i> to an undirected graph is made by first adding undirected edges between all nodes with a common child (including children that are value nodes). As value nodes do not have children, only edges between chance or decision nodes are added. Then we drop the directions on all arcs and finally remove all value nodes. The resulting ‘moral’ graph is denoted by <i>L<sup>m</sup></i>.</p>
		<p>Next, edges are added to the undirected graph <i>L<sup>m</sup></i> to form a triangulated graph <img src="formulas/31.gif">. The moral graph is triangulated so no additional edges are needed.</p>
		<p><img src="LIMID_files\figure_3.gif"></p>
		<p>After the moralization, we have to delete all utility nodes from graph.</p>
		<p>Finally the cliques <i>C</i> of <img src="formulas/31.gif"> are organized into a junction tree <i>T</i> having the property that for any node from the set of chance and division nodes, the collection of all cliques containing this node correspond to a connected subtree of <i>T</i>. </p>
		
		<p><h4>Steps of algorithm</h4></p>
		<p><b>Initialization</b></p>
		<p>Suppose we are given a LIMID <i>L</i> and the initial strategy <img src="formulas/2.gif">. To initialize the junction tree <i>T</i> one first associates a vacuous potential to each clique <img src="formulas/32.gif">. Then for each chance node <i>r</i> in <i>L</i>, <i>p<sub>r</sub></i> is multiplied onto the probability part of the potential of an arbitrary clique containing <i>fa(r)</i>. When this has been done, one takes each value node u and adds <i>U<sub>u</sub></i> to the utility part of the potential of any clique containing <i>pa(u)</i>.</p>
		<p>Let <img src="formulas/33.gif"> be the potential on clique <i>C</i> after these operations have been performed. The joint potential is equal to the combination of all the clique potentials and satisfies</p>
		<p><img src="formulas/34.gif"></p>
		<p>where ? - set of chance nodes, <img src="formulas/35.gif"> - set of decision nodes, <img src="formulas/36.gif"> - set of utility nodes.</p>
		<p><b>Collect propagation</b></p>
		<p>Let <img src="formulas/37.gif"> be a collection of potentials on the junction tree <i>T</i>. Let <img src="formulas/38.gif"> and suppose we wish to find the marginal <img src="formulas/39.gif"> for some clique <img src="formulas/40.gif">.</p>
		<p>To achieve our purpose we direct all the edges in <i>T</i> towards the ‘root-clique’ <img src="formulas/41.gif">. Then each clique passes a message to its child after having received messages from all its other neighbours. The structure of a message <img src="formulas/42.gif"> from clique <i>C<sub>1</sub></i> to its neighbor <i>C<sub>2</sub></i> is given by</p>
		<p><img src="formulas/43.gif"></p>
		<p><b>Local optimization</b></p>
		<p>Let <img src="formulas/13.gif"> be a potential. The contraction of <img src="formulas/29.gif"> is given as <img src="formulas/44.gif">. </p>
		<p><b>Theorem:</b> For a potential <img src="formulas/13.gif"> on <i>W</i> and <img src="formulas/27.gif"> we have </p>
		<p><img src="formulas/45.gif"></p>
		<p><b>Corollary:</b> Let the joint potential <img src="formulas/46.gif"> on the junction tree be given by</p>
		<p><img src="formulas/47.gif"></p>
		<p>where <img src="formulas/2.gif"> is a strategy. Then the expected utility of <i>q</i> is <img src="formulas/48.gif"></p>
		<p><br>So, a local maximum policy for strategy q at d can be found by carrying out the following steps:</p>
		<ol>
			<li><b>Retract:</b> Retract the policy for d from the potential on <i>R</i> to obtain <img src="formulas/49.gif">.</li>
			<li><b>Collect:</b> Collect to <i>R</i> to obtain <img src="formulas/50.gif">.</li>
			<li><b>Marginalize:</b> Compute <img src="formulas/51.gif">.</li>
			<li><b>Contract:</b> Compute the contraction <i>c<sub>fa(d)</sub></i> of <img src="formulas/52.gif">.</li>
			<li><b>Optimize:</b> For each <img src="formulas/53.gif">, find a point <img src="formulas/54.gif"> satisfying <img src="formulas/55.gif"> and define <img src="formulas/56.gif"> as the distribution degenerate at <img src="formulas/54.gif">. Add <img src="formulas/57.gif"> to the potential on <i>R</i> to get <img src="formulas/58.gif">.</li>
		</ol>
	</td></tr>
</table>

<hr><h4>Example 2-7. Running the inference on LIMID</h4>
<p>To start inference with LIMID Inference Engine you may use the following source code. </p>
<pre>
int main()
{
    pPigs->GetGraph()->Dump();

<font color="green">// - LIMID creation ---------------------------------------------------------</font>
  CIDNet* pPigs;
  pPigs = CreatePigsLIMID();
  
  <font color="green">// - Inference engine creation --------------------------------------------      </font>
  CLIMIDInfEngine *pInfEng = NULL;
  pInfEng = CLIMIDInfEngine::Create(pPigs);

<font color="green"> // - Run inference engine -------------------------------------------------</font>
  pInfEng->DoInference();

<font color="green">// - Get politics -----------------------------------------------------------</font>
    pFactorVector *Vec = pInfEng->GetPolitics();
    printf("\n=====================\nPolitics are:\n");
    for (int i = 0; i < Vec->size(); i++)
    {
      (*Vec)[i]->GetDistribFun()->Dump();
    }
    
<font color="green">// - Get expectation --------------------------------------------------------</font>
   float res = pInfEng->GetExpectation();
    printf("\nNumber of iterations is %d", pInfEng->GetIterNum());
    printf("\nExpectation is %.3f", res);

<font color="green">// - Free the memory --------------------------------------------------------</font>
  CLIMIDInfEngine::Release(&pInfEng);
  delete pPigs;

  return 0;
}
</pre>


<hr><h3><a name="ug_Learning">Learning for Bayesian and Markov Network</a></h3>

<p>
A graphical model can be defined by its structure and its set of parameters,
which are <i>conditional probability distributions</i> for dynamic and static Bayesian
networks and potentials for Markov network. Learning of a graphical model
consists in the estimation of model factors so as to ensure the best explanation
of information for the model.
</p><p>
Usually input data for learning is presented in a table, where columns
correspond to variables of the model and each row represents a learning sample
or observation. So, for example, See <a href="#table2_2">Table 2-2</a> for Sprinkler Model presents
the input data for the sprinkler model (<a href="#figWaterSprinkler"> Figure 2-1 </a>).
</p>

<CENTER>
<TABLE BORDER>
<CAPTION> <b><a name="table2_2">Table 2-2.</a> Learning Data for Sprinkler Model</b></CAPTION>
  <TR>
  <TH>Node 1</TH> <TH>Node 2</TH> <TH>Node 3</TH> <TH>Node 4</TH>
  </TR><TR>
  <TD>0</TD><TD>1</TD><TD>0</TD><TD>1</TD>
  </TR><TR>
  <TD>1</TD><TD>0</TD><TD>1</TD><TD>1</TD>
  </TR><TR>
  <TD>0</TD><TD>0</TD><TD>0</TD><TD>0</TD>
  </TR><TR>
  <TD>0</TD><TD>0</TD><TD>0</TD><TD>0</TD>
  </TR><TR>
  <TD>1</TD><TD>0</TD><TD>1</TD><TD>1</TD>
  </TR><TR>
  <TD>0</TD><TD>1</TD><TD>0</TD><TD>1</TD>
  </TR>
  </TABLE>
  </CENTER>

 <p>
If a variable is hidden, its value will be missing from the data for learning.
Samples in the table are assumed to be independent. The following four types of
learning tasks are distinguished to correspond to different a priori information <a href="openpnl_bibliography.htm#ref_Introd">[ Introd ]</a>:
</p>

<CENTER>
<TABLE BORDER>
<CAPTION><b>Types of Learning Tasks</b></CAPTION>
<TR>
<TH>Type of Task</TH> <TH>Graphical Model Structure</TH> <TH>Observability of Variables</TH>
</TR><TR>
<TD><a href = "#decl_Type1">Type1 </a></TD> <TD>known</TD> <TD>All variables are observed</TD>
</TR><TR>
<TD><a href = "#decl_Type2">Type2 </a></TD> <TD>known</TD> <TD>Some variables are not observed</TD>
</TR><TR>
<TD><a href = "#decl_Type3">Type3 </a></TD> <TD>unknown</TD> <TD>All variables are observed</TD>
</TR><TR>
<TD>Type 4</TD> <TD>unknown</TD> <TD>Some variables are not observed</TD>
</TR>
</TABLE>
</CENTER>

<blockquote>
<hr>
<b> NOTE. </b> <i>Only the first three types of learning tasks are considered below. Type
  four is not supported by the current version of PNL.</i>
<hr>
</blockquote>

<h4><a name="decl_Type1">Type 1 </a></h4>

<p>
This type of learning uses the ML algorithm which is based on <i>Maximum Likelihood Estimation </i>
<a href="openpnl_bibliography.htm#ref_JorBish">[ JorBish ]</a>. The algorithm estimates parameters of the graphical
model maximizing the value of the likelihood function <i>p(D|&theta;),</i> that is, the
probability of observability of learning data <i>D</i> for given parameters <i>&theta;.</i>
</p>

<h5><a name="decl_MLBayesian">Maximum Likelihood Estimation for Bayesian Network </a></h5>

<p>

<b>Discrete Case.</b> Consider the case when all variables of the network are discrete
<a href="openpnl_bibliography.htm#ref_JorBish">[ JorBish ]</a>. For a given Bayesian network denote the total number of its nodes
by <i>U.</i> For a certain node  the set of all its parents may be denoted by <i>&pi;<sub>&nu;</sub></i>
and  <i>&phi;<sub>&nu;</sub> = {&nu;}&cup; &pi;<sub>&nu;</sub></i>.
Let <i>A</i> be an arbitrary subset of nodes. Then <i>x<sub>A</sub></i> stands for a tuple of values for
the nodes from <i>A.</i> The count of observations, in which the nodes from the set <i>A</i>
assume values specified by <i>x<sub>A</sub></i> tuple, may be denoted by <i>m(x<sub>A</sub>)</i>. The logarithm of the
previously described likelihood function is more convenient than the function
itself. The logarithm may be found according to the formula:
</p>
<i>
l(&theta;, D)= log p(D|&theta;) = log( &prod;<sub>n</sub>p(x<sub>U, n</sub>|&theta;))
=&Sigma;<sub>x<sub>U</sub></sub>m(x<sub>U</sub>log p(x<sub>U</sub>)&theta;)=
&Sigma;<sub>&nu;</sub>&Sigma;<sub>x<sub>&phi;<sub>&nu;</sub></sub></sub> m(x<sub>&phi;<sub>&nu;</sub></sub> )
log &theta;<sub>&nu;</sub>(x<sub>&phi;<sub>&nu;</sub></sub>)
</i>

<p>
The values maximizing this function are:
</p>
<i>
p(x<sub>&nu;</sub>|x<sub>&phi;<sub>&nu;</sub></sub>) =
&theta;<sub>&nu;</sub>(x<sub>&phi;<sub>&nu;</sub></sub>) =
m(x<sub>&phi;<sub>&nu;</sub></sub>) / m(x<sub>&pi;<sub>&nu;</sub></sub>)
</i>
<p>
These estimates are formed independently for each node in the graph.
</p>
<p>
<b>Multivariate Gaussian Case.</b> In PNL the Multivariate Gaussian case is
implemented only for Bayesian networks.
The vector <i>x<sup>k</sup></i>  may be formed as follows:
<i>x<sup>k</sup></i>=(<i>y<sup>k</sup><sub>0</sub>,y<sup>k</sup><sub>1</sub>, ...,  </i>), where  and  are the vectors of values of
the <i>i-th</i> parent and its child in the <i>k-th</i> example of the table.
The current approach models the joint distribution over a node and its parents
as the multivariate Gaussian distribution and finds its Ml estimation. The
sufficient statistics after <i>N</i> examples are <a href="openpnl_bibliography.htm#ref_Murphy98">[ Murphy98 ]</a>, <a href="openpnl_bibliography.htm#ref_Jordan">[ Jordan ]</a>:
</p>
<i>
  &mu;=1/N &Sigma;x<sub>i</sub>, &Sigma; = 1/N &Sigma;<sub>i</sub>x<sub>i</sub>x<sub>i</sub><sup>T</sup>-&mu;&mu;<sup>T</sup>
</i>
<p>
<i>&Sigma;</i> and <i>&mu;</i> can be broken up into blocks corresponding to parent nodes and the child:
</p>
<img align=center src="fig/ugfig43.gif">, <i>&mu; = (&mu;<sub>y</sub>, &mu;<sub>x</sub>)<sup>T</sup></i>
<p>
The result is the Gaussian distribution at the child node in a moment notation:
</p>
<i>B</i>=&Sigma;<sub>xy</sub>&Sigma;<sub>yy</sub><sup>-1</sup>,
&mu;=&mu;<sub>x</sub>-<i>B</i>&mu;,
&Sigma;=&Sigma;<sub>xx</sub>-B&Sigma;<sub>yx</sub>,
<p>
where matrix <i>B</i>  is broken into individual blocks, one for each parent.
</p>
<hr><h5><a name="ug_LearningML">Maximum Likelihood Estimation for Markov Networ</a></h5>
<p>
Undirected models are more flexible than their directed counterparts. Assume
that all network variables are discrete. In this case, the log likelihood is
found as follows:
</p>
l(&theta; D)= log<i>p</i>(D|&theta;)=&Sigma;m(x<sub>C</sub>)log&psi;<sub>C</sub>(x<sub>C</sub>)-<i>N</i>log<i>Z</i>
<p>
where &psi;<sub>C</sub>(x<sub>C</sub>) is the clique potential, <i>N</i> is the number of evidences, and Z is the
normalization factor <a href="openpnl_bibliography.htm#ref_JorBish">[ JorBish ]</a>, <a href="openpnl_bibliography.htm#ref_Jirousek">[ Jirousek ]</a>.
</p>
<i>Z</i>=&Sigma;<sub>x<sub>&nu;</sub></sub>&Pi;<sub>C</sub>&psi;<sub>C</sub>(x<sub>C</sub>)
<p>
If potentials are defined on maximal cliques of the graph, the maximum
likelihood estimates for decomposable graphs can be found through inspection:
<LI>for every clique set the clique potential to the empirical marginal for
that clique;
<LI>for every non-empty intersection between cliquesassociate an empirical
marginal with the intersection, and divide that empirical marginal by the
potential of one of the two cliques that form the intersection.
</p>
<p>
If the graph is arbitrary, the <i>Iterative Proportional Fitting (IPF)</i> can be used
<a href="openpnl_bibliography.htm#ref_JorBish">[ JorBish ]</a>, <a href="openpnl_bibliography.htm#ref_Jirousek">[ Jirousek ]</a>. If the graph is decomposable, this algorithm
converges in a finite number of iterations, updating each potential once.
</p>
<p>
The IPF process runs as follows. Denote the potential of a clique <i>C</i> at <i>i-th</i>
iteration by &psi;<sub>C</sub><sup>i</sup>(x<sub>C</sub>)  and the joint probability distribution based on these parameter
estimates by <i>p</i><sup>i</sup>(<i>x</i>). In this notation the IPF can be written as follows:
</p>
<img align=center src="fig/ugfig54.gif">, where <img align=center src="fig/ugfig55.gif"> .
<p>
The normalization factor <i>Z</i> remains constant through all iteration process, so
IPF may be presented in terms of joint probabilities:
</p>
<img align=center src="fig/ugfig56.gif">
<p>
In PNL the estimation of Markov network parameters is based on IPF.

<hr><h4><a name="ug_BayesLerning">Bayesian Update</a></h4>

<p>
Besides factor parameters with exact values (such as, mean and variance in
Gaussian distribution), there are parameters in the form of unknown variables
which have their own probability distributions with other parameters, termed
<i>superparameters.</i> Superparameters are variables too, thus finally there appears
to be an infinite hierarchy of parameters. The current version of PNL supports
only a two-level hierarchy in discrete tabular distributions.
</p>
<p>
Let &theta; be a parameter of a probability distribution corresponding to some
variable.
<i>P</i>&theta; is a prior distribution of the parameter &theta;. The task of Bayesian parameter
learning is to update the given data <i>D</i>, that is to find the conditional
distribution <i>P</i>(&theta;|<i>D</i>).
According to the Bayes formula
</p>
<i>P(&theta;|i)=P(D|&theta;)P(D,&theta;)/P(D)</i>
where  <i>P(D)=&int;P(&theta;)P(D|&theta;).</i>
<p>
Based on the given parameter distribution function, the distribution function
for the unknown variable <i>x</i> is <i>P(x)=&int;P(&theta;)P(x|D)</i>
<p>
The Dirichlet distribution with parameters <i> a<sub>1</sub>,...,a<sub>n</sub> </i>
is a suitable prior distribution for
a discrete multinomial distribution (where a variable can give <i>n</i> outcomes) with
parameters &theta;<sub>1</sub>,..., &theta;<sub>n</sub>. Dirichlet parameters are interpreted in terms of pseudo counts,
where <i>a<sub>i</sub></i> stands for an imaginary observed number of cases when the discrete
variable has taken the <i>i-th</i> value. When training data contains a small number of
cases, positive pseudo counts allow to assign to its unobserved values a
non-zero probability.
</p>
<p>
Let training data contain <i>N<sub>1</sub>,...,N<sub>n</sub></i> cases, and <i>N<sub>i</sub></i> be a number of
cases when the <i>i-th</i> value is observed.
On learning these cases, a posterior distribution of &theta;  becomes a Dirichlet
distribution with parameters <i>a<sub>1</sub>+N<sub>1</sub>,...,a<sub>n</sub>+N<sub>n</sub></i>. The target
distribution of <i>x</i> after integration through parameters is<br>
<i>
  P(x=i)=(a<sub>i</sub>+N<sub>i</sub>)/&Sigma;(a<sub>k</sub>+N<sub>k</sub>)
</i>
</p>
<p>
This discussion applies to the case of an unconditional distribution where the
considered node of the BNet does not have parents. However, you may easily
extend it to cases when the node has parents. As there are counts <i>N<sub>ij</sub></i>  and pseudo
counts  <i>a<sub>ij</sub></i>, that correspond to the case when <i>x = j</i>, and parents of<i> x</i> are in
configuration <i>i</i>, the target distribution of <i>x</i> becomes
</p>
<i>
  P(x=i|parents &#60; x &#62; =i)=(a<sub>ij</sub>+N<sub>ij</sub>)/&Sigma;(a<sub>ik</sub>+N<sub>ik</sub>).
</i>

<h4><a name="decl_Type2">Type 2 </a></h4>

<p>
This type of inference uses the <i>Expectation Maximization (EM)</i> algorithm [Dempster ], <a href="openpnl_bibliography.htm#ref_Jordan">[ Jordan ]</a>.
The algorithm first assumes the initial state of parameters &theta;<sup>0</sup> and then starts the iterative
process alternately repeating two steps: E-step and M-step.
</p>
<p>
Consider the process at the <i>i-th</i> iteration:
</p>
<table border>

  <tr>
    <td>E-step</td> <td>For each example of the table the probability distribution of the
      unobserved variable is found from the values of observed variables and the
      current values of model parameters  <i>&theta;<sup>i-1</sup>.</i>
      The expectations of unobserved variables are calculated for each example in the table.</td>
  </tr>

  <tr>
    <td>M-step</td> <td>To maximize the value of the likelihood function, a new value of <i>&theta;<sup>i</sup></i> is found.</td>
  </tr>
</table>
<p>
E-step is repeated with the new parameter values.
This process converges to a local maximum.
In PNL the EM learning engine is implemented for:
<ul>
  <li>Bayesian networks with discrete or multivariate Gaussian distribution.
  <li>Markov networks with discrete distribution.
</ul>
The following example considers learning of parameters for the water-sprinkler
Bayesian network (see <a href="#figWaterSprinkler">Figure 2-1</a>). If all the nodes are observed,
learning <a href="#decl_Type1">Type 1</a> is used. In this case the E-step, which creates an inference
engine and performs the inference procedure, does not take place. If some nodes
are hidden, learning <a href="#decl_Type2">Type 2</a> is used. In this case the E-step takes place,
creating an instance of inference engine, which is a junction tree engine by
default.
</p>

<hr><h4><a name="exLearnWS">Example 2-8. Creation of learning engine for water-sprinkler BNet</a></h4>

<pre>
CBNet* pWSBnet = pnlExCreateWaterSprinklerBNet();
//create WS BNet with different matrices
std::cout&lt;&lt;"Learning procedure \n ";
CGraph *pGraph = CGraph::Copy( pWSBnet-&gt;GetGraph() );
CModelDomain *pMD = pWSBnet-&gt;GetModelDomain();
CBNet* pWSLearnBNet = CBNet::CreateWithRandomMatrices( pGraph, pMD );
//loading data from file
const char * fname = "..\\c_pgmtk\\examples\\Data\\casesForWS";
pEvidencesVector evVec;
if( ! pnlLoadEvidences(fname, &amp;evVec, pMD) )
{
    printf("can't open file with cases");
    exit(1);
}
int numOfSamples = evVec.size();
std::cout&lt;&lt;"Number of cases for learning = "&lt;&lt;numOfSamples&lt;&lt;std::endl;
//create learning engine
CEMLearningEngine *pLearn = CEMLearningEngine::Create( pWSLearnBNet );
//set data for learning
pLearn-&gt;SetData( numOfSamples, &amp;evVec.front() );
pLearn-&gt;Learn();
//get information from learned model
int nFactors = pWSLearnBNet-&gt;GetNumberOfFactors();
const CFactor *pCPD;
const CNumericDenseMatrix&lt;float&gt; *pMatForCPD;
int numOfEl;
const float *dataCPD;
int f;
for( f = 0; f &lt; nFactors; f++ )
{
    std::cout&lt;&lt;std::endl&lt;&lt;" probability distribution for node"&lt;&lt;f&lt;&lt;std::endl;
    pCPD = pWSLearnBNet-&gt;GetFactor(f);
    //all matrices are dense
    pMatForCPD = static_cast&lt;CNumericDenseMatrix&lt;float&gt; *&gt;(pCPD-&gt;GetMatrix(matTable));
    pMatForCPD-&gt;GetRawData( &amp;numOfEl, &amp;dataCPD );
    int j;
    for( j = 0; j &lt; numOfEl; j++ )
    {
    std::cout&lt;&lt;" "&lt;&lt;dataCPD[j];
    }
}
std::cout&lt;&lt;std::endl;
int ev;
for( ev = 0; ev &lt; evVec.size(); ev++ )
{
    delete evVec[ev];
}
delete pLearn;
delete pWSBnet;
delete pWSLearnBNet;
</pre>
  <p>
After learning parameters of the Bayesian network assume new values which
maximize the likelihood function. The new values correspond to the array of
learning data. The table with updated data may be used in further training in
the following two ways:
</p>
<p>
<b>Option 1.</b> Ignore the data of the previous learning. Use the <tt>SetData</tt> function to
implement the variant.
</p>

<hr><h4><a name="exLearnWSOption1">Example 2-9. Entering New Datat</a></h4>

<pre>
// entering new data and clear accumulated information.
// here pEvNew is the pointer to a newly created array of Evidences
pLearn-&gt;SetData( newNumOfCases, pEvNew)
// call learning
pLearn-&gt;Learn();

</pre>
<p>
The parameters of the Bayesian network assume new values that correspond to the
learning data.
</p>

<p>
<b>Option 2.</b> Use data from the previous learning. Use the <tt>ApprendData</tt> function to
implement the variant.
</p>

<hr><h4><a name="exLearnWSOption2">Example 2-10. Using data from previous learning</a></h4>

<pre>
pLearn-&gt;AppendData( newNumOfCases, pEvNew )
pLearn-&gt;Learn();

</pre>

<h4><a name="decl_Type3">Type 3 </a></h4>

<p>
The current version of PNL carries out structure learning for static BNets and
does not support other models. The learning engine calls Maximal Likelihood
parameter learning. In this version of PNL learning is carried out under the
condition that the input data is complete, that is, when all nodes of training
cases are observed. The algorithm supports graphical models with tabular
distributions.
</p>

<hr><h4><a name="ug_Metric">Structure Comparison Metrie</a></h4>

<p>
One of the solutions to the learning task in this case is the computation of
joint probability <i>p(D, S<sup>h</sup>)</i>
for the learning data <i>D</i> and the model structure  <i>S<sup>h</sup></i>:
</p>
<i>log p(D, S<sup>h</sup>) = log p(D | S<sup>h</sup>)+log p(S<sup>h</sup>)</i>.
<p>
In the case of a Bayesian network with discrete variables, the first item in the
above formula is found by applying <i>Bayesian Information Criterion (BIC)</i>
[Jordan]:
</p>
<i>log p(D | S<sup>h</sup>) &asymp; log p(D | &theta;, S<sup>h</sup>) - d/2*log&Lambda;</i> ,
<p>
where &theya;  stands for the network parameters, <i>N</i> is the number of observations, and <i>d</i>
is the number of network parameters. This criterion is a good approximation of
the ML criterion discussed above. In BIC the first item shows the degree of
consistency of the network parameters with the modelled data, and the addend
reflects the descriptive complexity of the network. Vector &theta;<sup>*</sup>  can be found by the
formula:
</p>
&theta;<sup>*</sup>=argmax<sub>&theta;</sub> log (p(D | &theta;, S<sup>h</sup>)p( &theta;| S<sup>h</sup>).
 <p>
The problem of selecting the most suitable Bayesian network from all network
configurations is NP hard. The algorithm implemented in PNL iterates through
all graph topologies that contain no directed
cycles. The total number of such topologies is  <i>2<sup>N(N-1)/2</sup></i>, where <i>N</i> is the number of
nodes, and <i>N!</i>  is the number of node permutations. The total number of Bayesian networks with the topology is
<i>N!*2<sup>N(N-1)/2</sup>.</i>
The following example considers structure learning for a Bayesian network using
<tt>CBICLearningEngine.</tt> This class is used for learning networks with discrete
parents only.
</p>
<hr><h4><a name="exLearnStruct">Example 2-11. Structure learning for Bayesian network using PNL</a></h4>

<pre>
// create an empty graph with number of nodes numOfNds
int numOfNds = 4;
CGraph *pGraph = CGraph::Create( numOfNds, NULL, NULL, NULL );
// here the user has to set all other variable values necessary to
//create a Bayesian network with an empty graph (the number of node
// types, actual node types, etc.)
const int numOfNdTypes = 1;
// number of node types is 1, because all nodes are of the same type
// all four are discrete and binary
CNodeType *nodeTypes = new CNodeType [numOfNdTypes];
int *nodeAssociation = new int [numOfNds];
nodeTypes[0].SetType(1, 2);// node type - discrete and binary
int i;
for( i = 0; i &lt; numOfNds; ++i )
{
    nodeAssociation[i] = 0;
}
pBNet = CBNet::Create( numOfNds, numOfNdTypes, nodeTypes, nodeAssociation, pGraph );
pBNet-&gt;AllocFactors();
for( i = 0; i &lt; numOfNds; i++ )
{
    pBNet-&gt;AllocFactor(i);
    pBNet-&gt;GetFactor(i)-&gt;CreateAllNecessaryMatrices();
}
// create learning engine
CBICLearningEngine *pLearn = CBICLearningEngine::Create( pBNet );
// set input data
pLearn-&gt;SetData(numOfCases, pEv);
//start learning
pLearn-&gt;Learn();
// the output Bayesian network
const CBNet *pFinalBNet = NULL;
pFinalBNet= static_cast&lt;const CBNet *&gt;(pLearn-&gt;GetGraphicalModel());
// the output graphical model is sorted topologically
// get the relation to initial node numeration
cost int *reordering = pLearn-&gt;GetOrder();

</pre>

<hr><h3><a name="ug_LearningDBN">Learning for DBNs</a></h3>

<p>
Parameter estimation algorithms for DBNs correspond to the
<i>Expectation Maximization (EM) </i> algorithms used for learning BNets. Note that the parameters
of a model must be tied across time-slices. Thus, sequences of unbounded length
may be modelled and the initial state of the dynamic system may be learned
independently of the transition matrix. The expected sufficient statistics
should be pooled for all the nodes that share the same parameters.
<p>
<hr><h4><a name="exLearnDBN">Example 2-12. Learning for DBN</a></h4>

<pre>
CBNet *pBNetForArHMM = pnlExCreateRndArHMM();
CDBN *pArHMM = CDBN::Create( pBNetForArHMM );
//Create learning procedure for DBN
pEvidencesVecVector evidencesOut;
const int nTimeSeries = 500;
intVector nSlices(nTimeSeries);
//define number of slices in the every time series
pnlRand(nTimeSeries, &amp;nSlices.front(), 3, 20);
// Generate evidences in a random way
pArHMM-&gt;GenerateSamples( &amp;evidencesOut, nSlices);
// Create DBN for learning
CDBN *pDBN = CDBN::Create(pnlExCreateRndArHMM());
// Create learning engine
CEMLearningEngineDBN *pLearn = CEMLearningEngineDBN::Create( pDBN );
// Set data for learning
pLearn-&gt;SetData( evidencesOut );
// Start learning
try
{
    pLearn-&gt;Learn();
}
catch(CAlgorithmicException except)
{
    std::cout &lt;&lt; except.GetMessage() &lt;&lt; std::endl;
}
//Iieo?aiea ?acoeuoaoia iao?aiea, ioia?a?aiea
int nFactors = pDBN-&gt;GetNumberOfFactors();
const CTabularDistribFun* pDistribFun;
const CFactor* pCPD;
int i;
for( i = 0; i &lt; nFactors; i++ )
{
    pCPD = pArHMM-&gt;GetFactor(i);
    int nnodes;
    const int* domain;
    pCPD-&gt;GetDomain( &amp;nnodes, &amp;domain );
    std::cout&lt;&lt;" node "&lt;&lt;domain[
    int node;
    for( node = 0; node &lt; nnodes-1; node++ )
    {
        std::cout&lt;&lt;domain[node]&lt;&lt;" ";
    }
    std::cout&lt;&lt;" Conditional probability distribution for node"&lt;&lt;i&lt;&lt;std::endl;
    std::cout&lt;&lt;" initial model"&lt;&lt;std::endl;
    pDistribFun = static_cast&lt;const
    CTabularDistribFun*&gt;(pCPD-&gt;GetDistribFun());
    pDistribFun-&gt;Dump();
    std::cout&lt;&lt;" model after learning"&lt;&lt;std::endl;
    pCPD = pDBN-&gt;GetFactor(i);
    pDistribFun = static_cast&lt;const
    CTabularDistribFun*&gt;(pCPD-&gt;GetDistribFun());
    pDistribFun-&gt;Dump();
}
for( i = 0; i &lt; evidencesOut.size(); i++ )
{
    int j;
    for( j = 0; j &lt; evidencesOut[i].size(); j++ )
    {
        delete evidencesOut[i][j];
    }
}
delete pDBN;
delete pArHMM;

</pre>

<hr><h3><a name="ug_SoftMax">SoftMax Distribution</a></h3>
<p>The SoftMax node (the node with softmax probability distribution) is a discrete node, which has continuous parents. Let SoftMax nodeY has m possible values. We define <br> <img src="formulas\formula_1.gif" align="center"> <br> where <i>b</i> and <i>W</i> is a parameters of SoftMax distribution. <i>W</i> is called weight matrix. It is two-dimensional matrix, it’s size is (Number of continuous parents)X(Number of SoftMax node states = <i>m</i>). In weight matrix columns are not independent. It is known that if we subtract last column from all, we’ll get <i>(m-1)</i> independent columns. That is why in our formula only first columns are used (<i>W<sub>j</sub></i> is a column of this matrix after subtraction). <i>b</i> is an offset vector. It has <i>m</i> elements, but they are not independent, to overcome dependences we have to subtract last offset vector element from all others. <p>When Softmax node has both discrete and continuous parents, we define probability distribution with weight matrix and offset vector r 		every possible state combination of discrete parents. Such distribution is called conditional SoftMax.</p>
<h4>One of the learn methods.</h4>
We want to execute learning process on Bayesian networks which include SoftMax  nodes. So, we have learning set for every node in SoftMax node family. This set consists of evidences on every node of the family, it is a matrix, where every coloumn represents one evidence, last element in a column is a SoftMax node value. Our goal is to find out softmax distribution parameters: weight matrix and offset vector.</p>
		<p>To solve this task we will use the following algorithm. Let’s form a likelihood function for softmax node.</p>
		<p><img src="formulas\formula_2.gif" align="center"></p>
		<p>Here <i>n</i> is quantity of experiments, <i>y<sub>i</sub></i>  is a value of SoftMax node in experiment number <i>i</i>. <i>m</i> is quantity of SoftMax node states. <i>X<sub>i</sub></i>  is a column of evidence matrix.</p>
		<p>To find real distribution parameters, we have to maximize Likelihood function by changing W and b. A point (W and b values), which corresponds to maximum Likelihood, is a point of real distribution parameters. In the case when we have large amount of evidences, Likelihood function is very close to zero. So, it’s better to use likelihood logarithm for maximizing. </p>
		<p><img src="formulas\formula_3.gif"></p>
		<p>To maximize LogLikelihood function, we have used three methods: Gradient method, Conjugate Gradient method and Newton-Ravsen method.</p>
<h4>Example of usage</h4>
Consider the following network.</p><img src="formulas\model.gif" align = "all"></img><br> <p>Nodes, which are marked by letter C are continuous, and nodes, which are marked by letter D are discrete. A SoftMax node (marked by letters SM) is a discrete node, which has both continuous and discrete parents. All discrete nodes have two possible states. The task is to find out the probability distribution on SoftMax node using evidences.</p>
			<p>Distribution on SoftMax node depends on distribution parameters of continous nodes, these dependences must be defined for every state configuration of discrete parents.</p>
			<p>To load this model you may use the following function:</p>
			<font class = "code">
			<pre>
CBNet* CreateSoftMaxExample(void)
{
  const int numOfNds = 5;
  int numOfNbrs[numOfNds] = { 1, 1, 1, 1, 4 };

  int nbrs0[] = { 4 };
  int nbrs1[] = { 4 };
  int nbrs2[] = { 4 };
  int nbrs3[] = { 4 };
  int nbrs4[] = { 0, 1, 2, 3};
    
  ENeighborType nbrsTypes0[] = { ntChild };
  ENeighborType nbrsTypes1[] = { ntChild };
  ENeighborType nbrsTypes2[] = { ntChild };
  ENeighborType nbrsTypes3[] = { ntChild };
  ENeighborType nbrsTypes4[] = { ntParent, ntParent, ntParent, ntParent };

  int *nbrs[] = { nbrs0, nbrs1, nbrs2, nbrs3, nbrs4 };
  ENeighborType *nbrsTypes[] = { nbrsTypes0, nbrsTypes1, nbrsTypes2, nbrsTypes3, nbrsTypes4};

  CGraph* pGraph = CGraph::Create( numOfNds, numOfNbrs, nbrs, nbrsTypes );
    
  <font color="green">//  Creation of the Model Domain.</font>
 
  CModelDomain* pMD;

  nodeTypeVector variableTypes;
    
  int nVariableTypes = 2;
  variableTypes.resize( nVariableTypes );
   
  variableTypes[0].SetType( 0, 1 ); <font color="green">// continuous node</font>
  variableTypes[1].SetType( 1, 2 ); <font color="green">// discrete node</font>
  
  intVector variableAssociation;  
  int nnodes = pGraph->GetNumberOfNodes();
  variableAssociation.assign(nnodes, 1);
  variableAssociation[0] = 0;
  variableAssociation[1] = 0;
  variableAssociation[2] = 1;
  variableAssociation[3] = 1;
  variableAssociation[4] = 1;

  pMD = CModelDomain::Create( variableTypes, variableAssociation );
    
<font color="green">  //  Creation base for BNet using Graph, and Model Domain</font>
    
  CBNet *pBNet = CBNet::Create(pGraph, pMD);
    
<font color="green">  //  Allocation space for all factors of the model</font>
  pBNet->AllocFactors();

<font color="green">  //  continous node 0</font>
  int nnodes0 = 1;
  int domain0[] = { 0 };
  float mean0 = 0.0f;
  float cov0 = 1.0f;
  CGaussianCPD *pCPD0 = CGaussianCPD::Create( domain0, nnodes0, pMD );
  pCPD0->AllocDistribution( &mean0, &cov0, 1.0f, NULL );
  pBNet->AttachFactor( pCPD0 );
  
<font color="green">  //  continuous node 1</font>
  int nnodes1 = 1;
  int domain1[] = { 1 };
  float mean1 = 0.0f;
  float cov1 = 1.0f;
  CGaussianCPD *pCPD1 = CGaussianCPD::Create( domain1, nnodes1, pMD );
  pCPD1->AllocDistribution( &mean1, &cov1, 1.0f, NULL );
  pBNet->AttachFactor( pCPD1 );

<font color="green">  //  discrete node 2</font>
  int nnodes2 = 1;
  int domain2[] = { 2 };
  float table2[] = { 0.7f, 0.3f};

  CTabularCPD *pCPD2 = CTabularCPD::Create( domain2, nnodes2, pMD, table2 );
  pCPD2->AllocMatrix(table2, matTable);
  pBNet->AttachParameter(pCPD2);

<font color="green">  //  discrete node 3</font>
  int nnodes3 = 1;
  int domain3[] = { 3 };
  float table3[] = { 0.4f, 0.6f};

  CTabularCPD *pCPD3 = CTabularCPD::Create( domain3, nnodes3, pMD, table3 );
  pCPD2->AllocMatrix(table3, matTable);
  pBNet->AttachParameter(pCPD3);


  <font color="green">// softmax  node 4</font>
  int nnodes4 = 5;
  int domain4[] = { 0, 1, 2, 3, 4 };
  CSoftMaxCPD *pCPD4 = CSoftMaxCPD::Create( domain4, nnodes4, pMD );

  <font color="green">//Defining the start SoftMax distribution parameters<br>  //for every state configuration of discrete parents </font>  
  int parInd00[] = { 0, 0 };

  float weight00[] = { 0.1f, 0.3f, 0.3f, 0.3f };
  float offset00[] = { 0.4f, 0.6f };
  
  pCPD4->AllocDistribution( weight00, offset00, parInd00 );
  
  int parInd01[] = { 0, 1 };

  float weight01[] = { 0.3f, 0.2f, 0.2f, 0.3f };
  float offset01[] = { 0.1f, 0.9f };

  pCPD4->AllocDistribution( weight01, offset01, parInd01 );

  int parInd10[] = { 1, 0 };

  float weight10[] = { 0.7f, 0.3f, 0.0f, 0.0f };
  float offset10[] = { 0.4f, 0.6f };

  pCPD4->AllocDistribution( weight10, offset10, parInd10 );
  
  int parInd11[] = { 1, 1 };

  float weight11[] = { 0.2f, 0.3f, 0.2f, 0.3f };
  float offset11[] = { 0.4f, 0.6f };

  pCPD4->AllocDistribution( weight11, offset11, parInd11 );

  pBNet->AttachFactor( pCPD4 );

  return pBNet;
}

			</pre>
To start learning  with this network you may use the following source code.
		<font class = "code">
		<pre>
int main()
{
<font color="green">//---- Network creation -----------------------------------------------------</font>
  CBNet *pBNet = NULL;
  pBNet = CreateSoftMaxExample();

<font color="green">//---- Learning engine creation ---------------------------------------------</font>
  CEMLearningEngine *pLearnEng = NULL;
  pLearnEng = CEMLearningEngine::Create(pBNet);

<font color="green">//---- Evidence Creation ----------------------------------------------------</font>   
  int NumOfNodes = pBNet->GetNumberOfNodes(); 
  valueVector vls;
  CEvidence **m_pEv;
  m_pEv = new CEvidence *[NumOfNodes];

   int nObsNds = NumOfNodes;
   const CModelDomain *pMD = pBNet->GetModelDomain();
   int *obsNds = new int [nObsNds];
   for (int i=0; i<nObsNds; i++) obsNds[i] = i;
   
   for (i = 0; i<&lt;> < </&lt;>10; i++)
  {
    GenerateSoftMaxEvidence(pBNet, -1.0, 1.0, vls);
    m_pEv[i] = CEvidence::Create( pMD, nObsNds, obsNds, vls );
  }
    
<font color="green">//---- Starting Learning process -------------------------------------------</font>  
  pLearnEng->SetData(10, m_pEv);
        
  pLearnEng->SetMaxIterEM(20);
  pLearnEng->SetMaximizeMethod(mmConjugateGradient);
  pLearnEng->Learn(); 
  
<font color="green">//---- Result Output --------------------------------------------------------</font>
  int numOfNdsTmp = pBNet->GetNumberOfNodes();
  for (i = 0; i < numOfNdsTmp; i++)
  {
    pBNet->GetFactor(i)->GetDistribFun()->Dump();
  }
    
<font color="green">//---- Free the Memory ------------------------------------------------------</font> 
  delete pLearnEng;
  delete pBNet;
  
  return 0;
}
		</pre>			


<hr><h3><a name="ug_DTree">Decision Tree Distribution</a></h3>
<p>Decision tree is a binary tree in which each node (except leaves – terminal nodes) contains a question with two possible answer: yes or no. For example, question may be: X is equal 5, or Y is greater than 2.5. Terminal node contains some “decision” that is taken when a descent on decision tree is finished in this node from the root through some questions. Decision tree may be effectively used in Bayesian networks to represent conditional discrete or continuous nodes, which really depend on a part of their parents or some parents configurations. This way lets to reduce amount of memory usage for such nodes and to compute nodes that have more than 400 parents. Of course, a list of possible questions, that may be used in decision tree node, must be specified and a necessary methods to form a tree in such node must be realized. </p>
<p><b>Simple examble</b></p>
<img src="LIMID_Files\bnet.gif" align="left"> <br>Consider a net that contains two discrete nodes d1, d2 and one tree node t1. Node sizes are 2, 3 and 2. <br>Nodes d1 and d2 are discrete parents of discrete tree node t1. 
Discrete node t1 has tree:	
 <img src="LIMID_Files\dt.gif" > Nodes n1, n2, and n5 are non-terminal nodes, n3, n4, n6 and n7 are terminal nodes.
		<br>Node n1 question is d1 = 0.
		<br>Node n2 question is d2 >= 1.
		<br>Node n5 question is d2 = 0.
		<br>Node n3 distribution is 0.5, 0.5.
		<br>Node n4 distribution is 0.7, 0.3.
		<br>Node n6 distribution is 0.4, 0.6.
		<br>Node n7 distribution is 0.3, 0.7.
<h4>One of the inference methods</h4>
We want to implement inference algorithm on Bayesian networks which include decision Tree  nodes. 
		Inference implementation in Bayesian networks, which include Decision Tree nodes, is possible when all asked parents of Decision Tree node are observed (otherwise it is imposible to find Decision Tree node distribution because there are no ways to the terminal node). In Gibbs Sampling Algorithm on each iteration all nodes ecxept one (current node) are pseudo-observed so we use it on networks with Decision Tree nodes.
	<br>Here is a short scheme of algorithm:
	<ul type=disc>
	<li>Potentials creation.
	<li>First sample generation.
	<li>Sample cycle.
	</ul>
On the first step a potential for every node in the net is created. If the initial node has tabular distribution, then potential will be Tabular, otherwise it will be Gaussian. In discrete case, distribution matrix equal  a vector with the lenth that is equal a node size.  
While generate the first sample, the descent on Desicion Tree node tree up to the terminal vertex are realized. This procedure is correct, because parent nodes values, which are already generated, are used and net is topologically sorted. After that we generate value on this node using distribution, which corresponds to definite terminal vertex.
<br>During the main cycle every node of the net is processed in two cases:
<ul type=disc>
<li>when a new value of the node is generated (in sample for this node);
<li>when a new value on one of the node parents is generated (in sample for parent).
</ul>
Handling processes in both situations are very close.
For generating new value on the node, we need to know marginal distribution on this node, which consider distributions on it’s children.

<h4>Example of usage</h4>

Consider the following network.</p><img src="LIMID_Files\bnet.gif" align = "all"></img><br> <p>Consider a net that contains two discrete nodes d1, d2 and one tree node t1. Node sizes are 2, 3 and 2. 
Nodes d1 and d2 are discrete parents of discrete tree node t1. The task is to find out the probability distribution on Desgion Tree node using evidence on somr of his parents.</p>
			<p>Distribution on decision Tree node depends on distribution parameters of continous nodes, these dependences must be defined with help of quiestions on non terminia nodes of decision Tree.</p>
			
</td>
</tr>
<tr>
<td>  <img src="LIMID_Files\dt.gif" > 
		</td><td align = "left"><br>Nodes n1, n2, and n5 are non-terminal nodes, n3, n4, n6 and n7 are terminal nodes.
		<br>Node n1 question is d1 = 0.
		<br>Node n2 question is d2 >= 1.
		<br>Node n5 question is d2 = 0.
		<br>Node n3 distribution is 0.5, 0.5.
		<br>Node n4 distribution is 0.7, 0.3.
		<br>Node n6 distribution is 0.4, 0.6.
		<br>Node n7 distribution is 0.3, 0.7.
  	</td>
</tr>
<tr>
<td colspan=2>
<p>To load this model you may use the following function:</p>
			<font class = "code">
			<pre>
CBNet* CreatedecisionTreeExample(void)
{
  //Creating Bayesian network</font>
const int nnodes = 3; <font color="green">//Number of nodes</font>
const int numNt = 2; <font color="green">//number of Node types (all nodes are discrete)</font>
CNodeType* nodeTypes = new CNodeType [numNt];
nodeTypes[0] = CNodeType( 1,2 ); <font color="green">// discrete node, size 2</font>
nodeTypes[1] = CNodeType( 1,3 ); <font color="green">// discrete node, size 3</font>
int nodeAssociation[] = { 0, 1, 0 };

int numOfNeigh[] = { 1, 1, 2 };
int neigh0[] = { 2 };
int neigh1[] = { 2 };
int neigh2[] = { 0, 1 };

ENeighborType orient0[] = { ntChild };
ENeighborType orient1[] = { ntChild };
ENeighborType orient2[] = { ntParent, ntParent };

int *neigh[] = { neigh0, neigh1, neigh2 };
ENeighborType *orient[] = { orient0, orient1, orient2 };

CGraph* pGraph = CGraph::Create(nnodes, numOfNeigh, neigh, orient);

<font color="green">//Create static BNet</font>
CBNet* pBNet = CBNet::Create(nnodes, numNt, nodeTypes, nodeAssociation, pGraph);
pBNet->AllocFactors();

int nnodes0 = 1;
int domain0[] = { 0 };
float table0[] = { 0.4f, 0.6f };
CTabularCPD *pCPD0 = CTabularCPD::Create(domain0, nnodes0, 
  pBNet->GetModelDomain(), table0);
pCPD0->AllocMatrix(table0, matTable);
pBNet->AttachFactor(pCPD0);

int nnodes1 = 1;
int domain1[] = { 1 };
float table1[] = { 0.4f, 0.1f, 0.5f };
CTabularCPD *pCPD1 = CTabularCPD::Create(domain1, nnodes1,
  pBNet->GetModelDomain(), table1);
pCPD0->AllocMatrix(table1, matTable);
pBNet->AttachFactor(pCPD1);

int nnodes2 = 3;
int domain2[] = { 0, 1, 2 };
CTreeCPD *pCPD2 = CTreeCPD::Create(domain2, nnodes2, 
  pBNet->GetModelDomain());

<font color="green">//creating tree on node t1</font>
const int nnodesT = 7; <font color="green">//Number of nodes in the tree</font>
int neigh0T[] = { 1, 2 };
int neigh1T[] = { 0, 3, 4 };
int neigh2T[] = { 0 };
int neigh3T[] = { 1 };
int neigh4T[] = { 1, 5, 6 };
int neigh5T[] = { 4 };
int neigh6T[] = { 4 };

ENeighborType orient0T[] = { ntChild, ntChild };
ENeighborType orient1T[] = { ntParent, ntChild, ntChild };
ENeighborType orient2T[] = { ntParent };
ENeighborType orient3T[] = { ntParent };
ENeighborType orient4T[] = { ntParent, , ntChild, ntChild };
ENeighborType orient5T[] = { ntParent };
ENeighborType orient6T[] = { ntParent };

int *neighT[] = { neigh0T, neigh1T, neigh2T, neigh3T, neigh4T, neigh5T, neigh6T };
ENeighborType *orientT[] = { orient0T, orient1T, orient2T, orient3T, orient4T, orient5T, orient6T };

CGraph* pGraphT = CGraph::Create(nnodesT, numOfNeighT, neighT, orientT);

<font color="green">// filling tree nodes values on node t1</font>
TreeNodeFields fnode0;
TreeNodeFields fnode1;
TreeNodeFields fnode2;
TreeNodeFields fnode3;
TreeNodeFields fnode4;
TreeNodeFields fnode5;
TreeNodeFields fnode6;

fnode0.isTerminal = false; <font color="green">// non-terminal node</font>
fnode0.Question = 0; <font color="green">// it means that question type is =</font>
fnode0.questionValue = 0; <font color="green">//it means that we ask value 0</font>
fnode0.node_index = 0; <font color="green">// asked node index</font> 

fnode1.isTerminal = false; <font color="green">// non-terminal node</font>
fnode1.Question = 1; <font color="green">//it means that question type is >=</font>
fnode1.questionValue = 1; <font color="green">//it means that we ask value 1</font>
fnode1.node_index = 1; <font color="green">// asked node index</font>

fnode2.isTerminal = true; <font color="green">// terminal node</font>
fnode2.probVect = new float[2];
fnode2.probVect[0] = 0.5f; <font color="green">// probability to take 0 on this node</font>
fnode2.probVect[1] = 0.5f; <font color="green">// probability to take 1 on this node</font>

fnode3.isTerminal = true;
fnode3.probVect = new float[2];
fnode3.probVect[0] = 0.7f; <font color="green">// probability to take 0 on this node</font>
fnode3.probVect[1] = 0.3f; <font color="green">// probability to take 1 on this node</font>

fnode4.isTerminal = false; <font color="green">// non-terminal node</font>
fnode4.Question = 0;  <font color="green">//it means that question type is =</font>
fnode4.questionValue = 0 <font color="green">//it means that we ask value 0</font>
fnode4.node_index = 1; <font color="green">// asked node index</font>

fnode5.isTerminal = true; <font color="green">// terminal node</font>
fnode5.probVect = new float[2];
fnode5.probVect[0] = 0.4f; <font color="green">// probability to take 0 on this node</font>
fnode5.probVect[1] = 0.6f; <font color="green">// probability to take 1 on this node</font>

fnode6.isTerminal = true; <font color="green">// terminal node</font>
fnode6.probVect = new float[2];
fnode6.probVect[0] = 0.3f; <font color="green">// probability to take 0 on this node</font>
fnode6.probVect[1] = 0.7f; <font color="green">// probability to take 1 on this node</font>

TreeNodeFields fields[7];
fields[0] = fnode0;
fields[1] = fnode1;
fields[2] = fnode2;
fields[3] = fnode3;
fields[4] = fnode4;
fields[5] = fnode5;
fields[6] = fnode6;

<font color="green">//follow function creates tree on decision tree node</font>
pCPD2->UpdateTree(pGraphT,fields);

pBNet->AttachFactor(pCPD2);

  return pBNet;
}

			</pre>
To start inference  with this network you may use the following source code.
		<font class = "code">
		<pre>
int main()
{
<font color="green">//---- Network creation -----------------------------------------------------</font>
  CBNet *pBNet = NULL;
  pBNet = CreatedecisionTreeExample();
<font color="green">//---- Inference engine creation ---------------------------------------------</font>
  CGibbsSamplingInfEngine *pGibbsInf;
  pGibbsInf = CGibbsSamplingInfEngine::Create( pBNet );
<font color="green">//---- Evidence Creation ----------------------------------------------------</font>   
  const int numOfObsNds  = 2;
  const int obsNds[]     = { 0, 1 }; 
  valueVector obsNdsVals(numOfObsNds);
  obsNdsVals[0].SetInt(0);
  obsNdsVals[1].SetInt(1);
	
  CEvidence *pEvidence = CEvidence::Create( pBNet, numOfObsNds, obsNds,
       obsNdsVals );   
<font color="green">//---- Starting Inference process -------------------------------------------</font>  
  pGibbsInf->SetMaxTime( 10000);
  pGibbsInf->SetBurnIn( 1000 );

  intVecVector queries(1);
  queries[0].clear();
  queries[0].push_back( 10 );
 
  pGibbsInf->SetQueries( queries );    
  pGibbsInf->EnterEvidence( pEvidence );
  
<font color="green">//---- Result Output --------------------------------------------------------</font>
  const int querySz1 = 1;
  const int query1[] = { 10 };
  pGibbsInf->MarginalNodes( query1, querySz1 );
    
  const CPotential *pQueryPot;
  pQueryPot = pGibbsInf->GetQueryJPD();
     
  pQueryPot->Dump();  
<font color="green">//---- Free the Memory ------------------------------------------------------</font> 
  delete pEvidence;
  delete pGibbsInf;
  delete pBNet;
  
  return 0;
}

		</pre>			


<hr><h3><a name="ug_LogSubsystem">Log Subsystem</a></h3>
<p>
<b>Attachment to Output and Dumping</b>
</p>
<p>
When a <em>Log</em> object is created it is automatically attached to the output. An embedded
type is dumped through Log interface. All strings dumped through Log have the prefix
of the first constructor argument. The second and the third constructor arguments
control filtering.</br>
When a <em>Log</em> object is created it is automatically attached to the multiplexor and when
the object is destroyed it is automatically detached from it.
</p>

<hr><h4><a name="exCode10">Example 2-13. Code example</a></h4>
<pre>
Class Point {
    double x, y, z;
    public:
    Point(double x_, double y_, double z_): x(x_), y(y_), z(z_) {}
    void dump() const;
};
void Point::dump() const
{
    Log out(“point: “, eLOG_INFO, eLOGSRV_PNL);
    out &lt;&lt; “x = “ &lt;&lt; x &lt;&lt; ‘\n’;
    out &lt;&lt; “y = “ &lt;&lt; y &lt;&lt; ‘\n’;
    out &lt;&lt; “z = “ &lt;&lt; z &lt;&lt; ‘\n’;
}
Point pt(1.0, 2.0, 3.0);
pt.dump();
</pre>
<p>
Devices which ensure outputting with level eLOG_INFO and service eLOGSRV_PNL
dump the following strings:
<li>point: x = 1.0
<li>point: y = 2.0
<li>point: z = 3.0
</p>
<p>
<b>Creating a <tt>Driver</tt></b><br>
When a driver is created it is automatically attached to the multiplexor. When a driver
is destroyed it is automatically detached from the multiplexor.
In the current version of PNL only one driver writes to std::ostream:LogDrvStream.
</p>
<hr><h4><a name="exCode10">Example 2-14. Code example</a></h4>
<pre>
{
LogDrvStream tempStream(“c:\\pnl_add.log”, eLOG_RESULT| eLOG_SYSERR|eLOG_PROGERR,eLOGSRV_ALL);
Log out(“demo out: ”, eLOG_RESULT|eLOG_DEBUG, eLOGSRV_PNL);
out &lt;&lt; “test string\n”;
…
}
</pre>
<p>
The driver tempStream is created before the implementation of the function. The
driver receives the logging information that corresponds to the given level and
service. Thus, for example, out dumps to tempStream.
</p>
<p>
<b>Description of Log Subsystem Classes</b></br>
<table border>

  <tr>
	  <td>Log</td> <td>Implements optimization. Has no virtual functions and does not presuppose derivation.</td>
  </tr>
  <tr>
	  <td>LogMultiplexor</td> <td>Implements commutation. There is only one LogMultiplexor and it does not have any derived classes.
		  Generally you do not create or destroy this class.</td>
  </tr>
  <tr>
	  <td>LogDriver</td> <td>Basic purely virtual class.
		  <li> LogDrvStream. This driver outputs to std::ostream. It
may be created by std::ostream. In this case you
need to delete std::ostream after destroing
LogDrvStream. It may also be created by the file name.
In this case the std::ostream is deleted by
LogDrvStream.
<li> LogDrvSystem. This driver resembles LogDrvStream
but is configured through ConfigureSystem, not
through Configure, so that its configuration cannot be
changed by LogMultiplexor.
</td>
</tr>
</table>
</p>
<p>
<b>Filtering Control</b></br>
Filtering is controled through a pair of parameters: level and service.
<ul>
<li>level identifies a type of information outputted through Log such as, for example,
a system error message eLOG_SYSERR or a message with debugging information
eLOG_DEBUG.</li>
<li>service identifies a part of the system from which the information comes.</li>
</ul>
Folowing table graphically represents level and service as they specify a subset of
rectangles.

</p>
<p>

<TABLE BORDER>
<CAPTION><b>Parameter graphic representation</b></CAPTION>
<tr>
	<td> </td> <td>eLOGSRV_LOG</td> <td>eLOGSRV_EXCEPTION_HANDLING</td> <td>eLOGSRV_POTENTIAL</td>
</tr>
<tr>
	<td>eLOG_RESULT</td> <td> </td> <td> </td> <td> </td>
</tr>
<tr>
	<td>eLOG_SYSERR</td> <td bgcolor=#a8a8a8>2</td> <td></td> <td bgcolor=#a8a8a8>2</td>
</tr>
<tr>
	<td>eLOG_PROGERR</td> <td> </td> <td bgcolor=#00fff>1</td> <td></td>
</tr>
<tr>
	<td>eLOG_WARNING</td> <td bgcolor=#a8a8a8>2</td><td></td> <td bgcolor=#a8a8a8>2</td>
</tr>
<tr>
	<td>eLOG_NOTICE</td>  <td bgcolor=#a8a8a8>2</td> <td> </td> <td bgcolor=#a8a8a8>2</td>
</tr>
<tr>
	<td>eLOG_INFO</td>    <td></td> <td bgcolor=#db9370>3</td> <tdbgcolor=#db9370>3</td>
</tr>
<tr>
	<td>eLOG_DEBUG</td>   <td></td> <td bgcolor=#db9370>3</td> <td bgcolor=#db9370>3</td>
</tr>
</table>
</p>
<p>
<li>[eLOG_PROGERR, eLOGSRV_EXCEPTION_HANDLING]
<li>[eLOG_SYSERR|eLOG_WARNING|eLOG_NOTICE,eLOGSRV_LOG|eLOGSRV_POTENTIAL]
<li>[eLOG_INFO|eLOG_DEBUG,eLOGSRV_EXCEPTION_HANDLING|eLOGSRV_POTENTIAL]
</p>
</body>
</html>
